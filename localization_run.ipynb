{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1kPHYJiOt0jF",
        "outputId": "59ba15ab-1c9c-44b9-adbe-d923039ecd53"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'indoor_localization_oxford_dataset'...\n",
            "warning: Could not find remote branch 09cf7d140a98789db0ef2661a60056613655ac2e to clone.\n",
            "fatal: Remote branch 09cf7d140a98789db0ef2661a60056613655ac2e not found in upstream origin\n",
            "\n",
            "\n",
            "\u001b7\u001b[1A\u001b[1G\u001b[27G[Files: 0  Bytes: 0  [0 B/s] Re]\u001b8\u001b7\u001b[2A\u001b[1G\u001b[27G[https://jimchen4214-public.s3.]\u001b8\u001b7\u001b[2A\u001b[1Gdata.zip               0% [>                             ]   16.54K    --.-KB/s\u001b8\u001b7\u001b[2A\u001b[1Gdata.zip               0% [>                             ]   50.54K  136.00KB/s\u001b8\u001b7\u001b[2A\u001b[1Gdata.zip               0% [>                             ]  118.54K  272.00KB/s\u001b8\u001b7\u001b[2A\u001b[1Gdata.zip               0% [>                             ]  288.54K  435.19KB/s\u001b8\u001b7\u001b[2A\u001b[1Gdata.zip               0% [>                             ]  594.54K  659.81KB/s\u001b8\u001b7\u001b[2A\u001b[1Gdata.zip               0% [>                             ]    1.16M    1.14MB/s\u001b8\u001b7\u001b[2A\u001b[1Gdata.zip               0% [>                             ]    1.19M    1.04MB/s\u001b8\u001b7\u001b[2A\u001b[1Gdata.zip               0% [>                             ]    1.94M    1.53MB/s\u001b8\u001b7\u001b[2A\u001b[1Gdata.zip               0% [>                             ]    1.99M    1.43MB/s\u001b8\u001b7\u001b[2A\u001b[1Gdata.zip               0% [>                             ]    2.22M    1.47MB/s\u001b8\u001b7\u001b[2A\u001b[1Gdata.zip               0% [>                             ]    3.06M    1.87MB/s\u001b8\u001b7\u001b[2A\u001b[1Gdata.zip               0% [>                             ]    3.64M    2.07MB/s\u001b8\u001b7\u001b[2A\u001b[1Gdata.zip               0% [>                             ]    3.77M    1.87MB/s\u001b8\u001b7\u001b[2A\u001b[1Gdata.zip               0% [>                             ]    5.17M    2.29MB/s\u001b8\u001b7\u001b[2A\u001b[1Gdata.zip               0% [>                             ]    5.86M    2.22MB/s\u001b8\u001b7\u001b[2A\u001b[1Gdata.zip               0% [>                             ]    6.55M    2.27MB/s\u001b8\u001b7\u001b[2A\u001b[1Gdata.zip               0% [>                             ]    7.27M    2.31MB/s\u001b8\u001b7\u001b[2A\u001b[1Gdata.zip               0% [>                             ]    7.99M    2.27MB/s\u001b8\u001b7\u001b[2A\u001b[1Gdata.zip               0% [>                             ]    8.74M    2.32MB/s\u001b8\u001b7\u001b[2A\u001b[1Gdata.zip               0% [>                             ]    9.49M    2.29MB/s\u001b8\u001b7\u001b[2A\u001b[1Gdata.zip               1% [>                             ]   10.25M    2.40MB/s\u001b8\u001b7\u001b[2A\u001b[1Gdata.zip               1% [>                             ]   11.02M    2.44MB/s\u001b8\u001b7\u001b[2A\u001b[1Gdata.zip               1% [>                             ]   11.69M    2.45MB/s\u001b8\u001b7\u001b[2A\u001b[1Gdata.zip               1% [>                             ]   12.11M    2.35MB/s\u001b8\u001b7\u001b[2A\u001b[1Gdata.zip               1% [>                             ]   12.66M    2.45MB/s\u001b8\u001b7\u001b[2A\u001b[1Gdata.zip               1% [>                             ]   13.24M    2.43MB/s\u001b8\u001b7\u001b[2A\u001b[1Gdata.zip               1% [>                             ]   13.81M    2.51MB/s\u001b8"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/jimchen2/indoor_localization_oxford_dataset.git && cd indoor_localization_oxford_dataset && git checkout 09cf7d140a98789db0ef2661a60056613655ac2\n",
        "!wget https://jimchen4214-public.s3.us-east-1.amazonaws.com/other/data.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zvo8a2x33V5n"
      },
      "outputs": [],
      "source": [
        "!mv data.zip indoor_localization_oxford_dataset/."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jGdwLbe23zBl",
        "outputId": "a50e1b31-ee42-4108-8274-9e772d150e89"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/indoor_localization_oxford_dataset/indoor_localization_oxford_dataset\n",
            "data  data.zip\tdeprecated  docs  model  README.md  requirements.txt  src\n"
          ]
        }
      ],
      "source": [
        "%cd indoor_localization_oxford_dataset\n",
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ynzv6rub3hHv",
        "outputId": "29ce703b-c862-4627-e43d-a0486dc804a3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  data.zip\n",
            "   creating: data/Oxford Inertial Odometry Dataset/large scale/\n",
            "  inflating: data/Oxford Inertial Odometry Dataset/large scale/.DS_Store  \n",
            "   creating: data/Oxford Inertial Odometry Dataset/large scale/floor4/\n",
            "  inflating: data/Oxford Inertial Odometry Dataset/large scale/floor4/.DS_Store  \n",
            "   creating: data/Oxford Inertial Odometry Dataset/large scale/floor4/tango/\n",
            "  inflating: data/Oxford Inertial Odometry Dataset/large scale/floor4/tango/tango11.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/large scale/floor4/tango/tango10.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/large scale/floor4/tango/tango12.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/large scale/floor4/tango/tango13.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/large scale/floor4/tango/tango17.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/large scale/floor4/tango/tango16.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/large scale/floor4/tango/tango14.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/large scale/floor4/tango/tango8.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/large scale/floor4/tango/tango9.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/large scale/floor4/tango/tango15.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/large scale/floor4/tango/tango18.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/large scale/floor4/tango/tango4.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/large scale/floor4/tango/tango5.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/large scale/floor4/tango/tango7.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/large scale/floor4/tango/tango6.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/large scale/floor4/tango/tango2.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/large scale/floor4/tango/tango3.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/large scale/floor4/tango/tango1.csv  \n",
            "   creating: data/Oxford Inertial Odometry Dataset/large scale/floor4/tango/raw/\n",
            "  inflating: data/Oxford Inertial Odometry Dataset/large scale/floor4/tango/raw/2017-08-31_17-39-05_pose.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/large scale/floor4/tango/raw/2017-08-31_18-04-14_pose.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/large scale/floor4/tango/raw/2017-08-31_17-55-30_pose.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/large scale/floor4/tango/raw/2017-08-31_18-16-06_pose.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/large scale/floor4/tango/raw/2017-08-31_17-25-18_pose.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/large scale/floor4/tango/raw/2017-08-31_17-28-33_pose.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/large scale/floor4/tango/raw/2017-08-31_18-11-30_pose.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/large scale/floor4/tango/raw/2017-08-31_17-31-54_pose.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/large scale/floor4/tango/raw/2017-08-31_17-11-05_pose.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/large scale/floor4/tango/raw/2017-08-31_17-43-04_pose.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/large scale/floor4/tango/raw/2017-08-31_17-47-09_pose.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/large scale/floor4/tango/raw/2017-08-31_17-51-13_pose.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/large scale/floor4/tango/raw/2017-08-31_17-35-25_pose.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/large scale/floor4/tango/raw/2017-08-31_18-08-00_pose.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/large scale/floor4/tango/raw/2017-08-31_17-21-57_pose.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/large scale/floor4/tango/raw/2017-08-31_17-14-44_pose.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/large scale/floor4/tango/raw/2017-08-31_17-18-45_pose.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/large scale/floor4/tango/raw/2017-08-31_18-00-27_pose.csv  \n",
            "   creating: data/Oxford Inertial Odometry Dataset/large scale/floor4/syn/\n",
            "  inflating: data/Oxford Inertial Odometry Dataset/large scale/floor4/syn/imu1.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/large scale/floor4/syn/imu2.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/large scale/floor4/syn/imu3.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/large scale/floor4/syn/imu7.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/large scale/floor4/syn/imu6.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/large scale/floor4/syn/imu4.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/large scale/floor4/syn/imu5.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/large scale/floor4/syn/tango11.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/large scale/floor4/syn/tango10.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/large scale/floor4/syn/tango12.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/large scale/floor4/syn/tango13.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/large scale/floor4/syn/tango17.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/large scale/floor4/syn/tango16.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/large scale/floor4/syn/imu18.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/large scale/floor4/syn/tango14.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/large scale/floor4/syn/tango8.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/large scale/floor4/syn/tango9.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/large scale/floor4/syn/tango15.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/large scale/floor4/syn/imu16.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/large scale/floor4/syn/tango18.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/large scale/floor4/syn/tango4.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/large scale/floor4/syn/tango5.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/large scale/floor4/syn/imu17.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/large scale/floor4/syn/imu15.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/large scale/floor4/syn/tango7.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/large scale/floor4/syn/tango6.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/large scale/floor4/syn/imu14.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/large scale/floor4/syn/imu10.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/large scale/floor4/syn/tango2.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/large scale/floor4/syn/tango3.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/large scale/floor4/syn/imu11.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/large scale/floor4/syn/imu13.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/large scale/floor4/syn/tango1.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/large scale/floor4/syn/imu12.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/large scale/floor4/syn/imu8.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/large scale/floor4/syn/imu9.csv  \n",
            "   creating: data/Oxford Inertial Odometry Dataset/large scale/floor4/raw/\n",
            "  inflating: data/Oxford Inertial Odometry Dataset/large scale/floor4/raw/imu1.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/large scale/floor4/raw/imu2.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/large scale/floor4/raw/imu3.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/large scale/floor4/raw/imu7.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/large scale/floor4/raw/imu6.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/large scale/floor4/raw/imu4.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/large scale/floor4/raw/imu5.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/large scale/floor4/raw/imu18.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/large scale/floor4/raw/imu16.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/large scale/floor4/raw/imu17.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/large scale/floor4/raw/imu15.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/large scale/floor4/raw/imu14.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/large scale/floor4/raw/imu10.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/large scale/floor4/raw/imu11.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/large scale/floor4/raw/imu13.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/large scale/floor4/raw/imu12.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/large scale/floor4/raw/imu8.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/large scale/floor4/raw/imu9.csv  \n",
            "   creating: data/Oxford Inertial Odometry Dataset/large scale/floor1/\n",
            "   creating: data/Oxford Inertial Odometry Dataset/large scale/floor1/tango/\n",
            "  inflating: data/Oxford Inertial Odometry Dataset/large scale/floor1/tango/tango10.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/large scale/floor1/tango/tango8.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/large scale/floor1/tango/tango9.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/large scale/floor1/tango/tango4.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/large scale/floor1/tango/tango5.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/large scale/floor1/tango/tango7.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/large scale/floor1/tango/tango6.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/large scale/floor1/tango/tango2.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/large scale/floor1/tango/tango3.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/large scale/floor1/tango/tango1.csv  \n",
            "   creating: data/Oxford Inertial Odometry Dataset/large scale/floor1/tango/20170901/\n",
            "  inflating: data/Oxford Inertial Odometry Dataset/large scale/floor1/tango/20170901/2017-09-01_16-43-27_pose.csv  \n",
            " extracting: data/Oxford Inertial Odometry Dataset/large scale/floor1/tango/20170901/2017-09-01_16-41-17_pose.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/large scale/floor1/tango/20170901/2017-09-01_17-03-54_pose.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/large scale/floor1/tango/20170901/2017-09-01_16-57-07_wifi.csv  \n",
            " extracting: data/Oxford Inertial Odometry Dataset/large scale/floor1/tango/20170901/2017-09-01_16-32-07_pose.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/large scale/floor1/tango/20170901/2017-09-01_16-53-58_data.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/large scale/floor1/tango/20170901/2017-09-01_16-39-05_wifi.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/large scale/floor1/tango/20170901/2017-09-01_16-46-54_data.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/large scale/floor1/tango/20170901/2017-09-01_16-54-06_pose.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/large scale/floor1/tango/20170901/2017-09-01_17-07-47_pose.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/large scale/floor1/tango/20170901/2017-09-01_17-11-14_pose.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/large scale/floor1/tango/20170901/2017-09-01_16-50-39_data.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/large scale/floor1/tango/20170901/2017-09-01_16-32-16_pose.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/large scale/floor1/tango/20170901/2017-09-01_17-00-35_pose.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/large scale/floor1/tango/20170901/2017-09-01_16-46-34_data.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/large scale/floor1/tango/20170901/2017-09-01_16-50-54_pose.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/large scale/floor1/tango/20170901/2017-09-01_16-57-07_data.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/large scale/floor1/tango/20170901/2017-09-01_16-35-48_pose.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/large scale/floor1/tango/20170901/2017-09-01_16-47-41_pose.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/large scale/floor1/tango/20170901/2017-09-01_16-50-39_wifi.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/large scale/floor1/tango/20170901/2017-09-01_17-14-43_pose.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/large scale/floor1/tango/20170901/2017-09-01_16-57-14_pose.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/large scale/floor1/tango/20170901/2017-09-01_16-46-34_wifi.csv  \n",
            " extracting: data/Oxford Inertial Odometry Dataset/large scale/floor1/tango/20170901/2017-09-01_16-40-45_pose.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/large scale/floor1/tango/20170901/2017-09-01_16-39-05_data.csv  \n",
            " extracting: data/Oxford Inertial Odometry Dataset/large scale/floor1/tango/20170901/2017-09-01_16-46-54_wifi.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/large scale/floor1/tango/20170901/2017-09-01_16-32-41_pose.csv  \n",
            "   creating: data/Oxford Inertial Odometry Dataset/large scale/floor1/syn/\n",
            "  inflating: data/Oxford Inertial Odometry Dataset/large scale/floor1/syn/imu1.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/large scale/floor1/syn/imu2.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/large scale/floor1/syn/imu3.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/large scale/floor1/syn/imu7.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/large scale/floor1/syn/imu6.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/large scale/floor1/syn/imu4.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/large scale/floor1/syn/imu5.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/large scale/floor1/syn/tango10.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/large scale/floor1/syn/tango8.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/large scale/floor1/syn/tango9.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/large scale/floor1/syn/tango4.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/large scale/floor1/syn/tango5.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/large scale/floor1/syn/tango7.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/large scale/floor1/syn/tango6.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/large scale/floor1/syn/imu10.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/large scale/floor1/syn/tango2.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/large scale/floor1/syn/tango3.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/large scale/floor1/syn/tango1.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/large scale/floor1/syn/imu8.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/large scale/floor1/syn/imu9.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/large scale/floor1/large scale.xlsx  \n",
            "   creating: data/Oxford Inertial Odometry Dataset/large scale/floor1/raw/\n",
            "  inflating: data/Oxford Inertial Odometry Dataset/large scale/floor1/raw/imu1.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/large scale/floor1/raw/imu2.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/large scale/floor1/raw/imu3.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/large scale/floor1/raw/imu7.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/large scale/floor1/raw/imu6.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/large scale/floor1/raw/imu4.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/large scale/floor1/raw/imu5.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/large scale/floor1/raw/imu10.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/large scale/floor1/raw/imu11.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/large scale/floor1/raw/imu8.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/large scale/floor1/raw/imu9.csv  \n",
            "   creating: data/Oxford Inertial Odometry Dataset/multi devices/\n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi devices/multi devices.xlsx  \n",
            "   creating: data/Oxford Inertial Odometry Dataset/multi devices/iPhone 5/\n",
            "   creating: data/Oxford Inertial Odometry Dataset/multi devices/iPhone 5/syn/\n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi devices/iPhone 5/syn/imu1.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi devices/iPhone 5/syn/vi3.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi devices/iPhone 5/syn/vi2.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi devices/iPhone 5/syn/imu2.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi devices/iPhone 5/syn/vi1.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi devices/iPhone 5/syn/imu3.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi devices/iPhone 5/syn/imu7.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi devices/iPhone 5/syn/vi5.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi devices/iPhone 5/syn/vi4.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi devices/iPhone 5/syn/imu6.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi devices/iPhone 5/syn/imu4.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi devices/iPhone 5/syn/vi6.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi devices/iPhone 5/syn/vi7.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi devices/iPhone 5/syn/imu5.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi devices/iPhone 5/syn/imu8.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi devices/iPhone 5/syn/imu9.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi devices/iPhone 5/syn/vi9.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi devices/iPhone 5/syn/vi8.csv  \n",
            "   creating: data/Oxford Inertial Odometry Dataset/multi devices/iPhone 5/raw/\n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi devices/iPhone 5/raw/imu1.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi devices/iPhone 5/raw/vi3.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi devices/iPhone 5/raw/vi2.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi devices/iPhone 5/raw/imu2.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi devices/iPhone 5/raw/vi1.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi devices/iPhone 5/raw/imu3.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi devices/iPhone 5/raw/imu7.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi devices/iPhone 5/raw/vi5.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi devices/iPhone 5/raw/vi4.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi devices/iPhone 5/raw/imu6.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi devices/iPhone 5/raw/imu4.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi devices/iPhone 5/raw/vi6.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi devices/iPhone 5/raw/vi7.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi devices/iPhone 5/raw/imu5.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi devices/iPhone 5/raw/imu8.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi devices/iPhone 5/raw/imu9.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi devices/iPhone 5/raw/vi9.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi devices/iPhone 5/raw/vi8.csv  \n",
            "   creating: data/Oxford Inertial Odometry Dataset/multi devices/nexus 5/\n",
            "   creating: data/Oxford Inertial Odometry Dataset/multi devices/nexus 5/syn/\n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi devices/nexus 5/syn/imu1.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi devices/nexus 5/syn/vi3.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi devices/nexus 5/syn/vi2.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi devices/nexus 5/syn/imu2.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi devices/nexus 5/syn/vi1.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi devices/nexus 5/syn/imu3.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi devices/nexus 5/syn/imu7.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi devices/nexus 5/syn/vi5.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi devices/nexus 5/syn/vi4.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi devices/nexus 5/syn/imu6.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi devices/nexus 5/syn/imu4.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi devices/nexus 5/syn/vi6.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi devices/nexus 5/syn/vi7.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi devices/nexus 5/syn/imu5.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi devices/nexus 5/syn/imu8.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi devices/nexus 5/syn/vi8.csv  \n",
            "   creating: data/Oxford Inertial Odometry Dataset/multi devices/nexus 5/raw/\n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi devices/nexus 5/raw/imu1.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi devices/nexus 5/raw/vi3.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi devices/nexus 5/raw/vi2.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi devices/nexus 5/raw/imu2.csv  \n",
            "   creating: data/Oxford Inertial Odometry Dataset/multi devices/nexus 5/raw/nexus-20171228T205751Z-001/\n",
            "   creating: data/Oxford Inertial Odometry Dataset/multi devices/nexus 5/raw/nexus-20171228T205751Z-001/nexus/\n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi devices/nexus 5/raw/nexus-20171228T205751Z-001/nexus/2017-12-28_17-38-26_wifi.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi devices/nexus 5/raw/nexus-20171228T205751Z-001/nexus/2017-12-28_19-58-53_data.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi devices/nexus 5/raw/nexus-20171228T205751Z-001/nexus/2017-12-28_18-48-11_data.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi devices/nexus 5/raw/nexus-20171228T205751Z-001/nexus/2017-12-28_18-00-17_data.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi devices/nexus 5/raw/nexus-20171228T205751Z-001/nexus/2017-12-28_17-49-51_data.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi devices/nexus 5/raw/nexus-20171228T205751Z-001/nexus/2017-12-28_18-37-50_steps.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi devices/nexus 5/raw/nexus-20171228T205751Z-001/nexus/2017-12-28_18-58-35_steps.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi devices/nexus 5/raw/nexus-20171228T205751Z-001/nexus/2017-12-28_18-37-50_wifi.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi devices/nexus 5/raw/nexus-20171228T205751Z-001/nexus/2017-12-28_18-48-11_steps.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi devices/nexus 5/raw/nexus-20171228T205751Z-001/nexus/2017-12-28_18-58-35_data.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi devices/nexus 5/raw/nexus-20171228T205751Z-001/nexus/2017-12-28_20-02-09_steps.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi devices/nexus 5/raw/nexus-20171228T205751Z-001/nexus/2017-12-28_17-38-26_data.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi devices/nexus 5/raw/nexus-20171228T205751Z-001/nexus/2017-12-28_19-58-53_wifi.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi devices/nexus 5/raw/nexus-20171228T205751Z-001/nexus/2017-12-28_17-49-51_wifi.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi devices/nexus 5/raw/nexus-20171228T205751Z-001/nexus/2017-12-28_19-58-53_steps.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi devices/nexus 5/raw/nexus-20171228T205751Z-001/nexus/2017-12-28_18-37-50_data.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi devices/nexus 5/raw/nexus-20171228T205751Z-001/nexus/2017-12-28_17-49-51_steps.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi devices/nexus 5/raw/nexus-20171228T205751Z-001/nexus/2017-12-28_17-38-26_steps.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi devices/nexus 5/raw/nexus-20171228T205751Z-001/nexus/2017-12-28_18-00-17_steps.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi devices/nexus 5/raw/nexus-20171228T205751Z-001/nexus/2017-12-28_20-02-09_data.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi devices/nexus 5/raw/vi1.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi devices/nexus 5/raw/imu3.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi devices/nexus 5/raw/imu7.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi devices/nexus 5/raw/vi5.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi devices/nexus 5/raw/vi4.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi devices/nexus 5/raw/imu6.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi devices/nexus 5/raw/imu4.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi devices/nexus 5/raw/vi6.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi devices/nexus 5/raw/vi7.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi devices/nexus 5/raw/imu5.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi devices/nexus 5/raw/imu8.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi devices/nexus 5/raw/vi8.csv  \n",
            "   creating: data/Oxford Inertial Odometry Dataset/multi devices/iPhone 6/\n",
            "   creating: data/Oxford Inertial Odometry Dataset/multi devices/iPhone 6/syn/\n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi devices/iPhone 6/syn/imu1.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi devices/iPhone 6/syn/vi3.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi devices/iPhone 6/syn/vi2.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi devices/iPhone 6/syn/imu2.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi devices/iPhone 6/syn/vi1.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi devices/iPhone 6/syn/imu3.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi devices/iPhone 6/syn/imu7.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi devices/iPhone 6/syn/vi5.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi devices/iPhone 6/syn/vi4.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi devices/iPhone 6/syn/imu6.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi devices/iPhone 6/syn/imu4.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi devices/iPhone 6/syn/vi6.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi devices/iPhone 6/syn/vi7.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi devices/iPhone 6/syn/imu5.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi devices/iPhone 6/syn/imu8.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi devices/iPhone 6/syn/imu9.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi devices/iPhone 6/syn/vi9.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi devices/iPhone 6/syn/vi8.csv  \n",
            "   creating: data/Oxford Inertial Odometry Dataset/multi devices/iPhone 6/raw/\n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi devices/iPhone 6/raw/imu1.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi devices/iPhone 6/raw/vi3.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi devices/iPhone 6/raw/vi2.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi devices/iPhone 6/raw/imu2.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi devices/iPhone 6/raw/vi1.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi devices/iPhone 6/raw/imu3.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi devices/iPhone 6/raw/imu7.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi devices/iPhone 6/raw/vi5.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi devices/iPhone 6/raw/vi4.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi devices/iPhone 6/raw/imu6.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi devices/iPhone 6/raw/imu4.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi devices/iPhone 6/raw/vi6.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi devices/iPhone 6/raw/vi7.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi devices/iPhone 6/raw/imu5.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi devices/iPhone 6/raw/imu8.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi devices/iPhone 6/raw/imu9.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi devices/iPhone 6/raw/vi9.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi devices/iPhone 6/raw/vi8.csv  \n",
            "   creating: data/Oxford Inertial Odometry Dataset/pocket/\n",
            "  inflating: data/Oxford Inertial Odometry Dataset/pocket/.DS_Store  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/pocket/Train.txt  \n",
            "   creating: data/Oxford Inertial Odometry Dataset/pocket/data1/\n",
            "  inflating: data/Oxford Inertial Odometry Dataset/pocket/data1/.DS_Store  \n",
            "   creating: data/Oxford Inertial Odometry Dataset/pocket/data1/syn/\n",
            "  inflating: data/Oxford Inertial Odometry Dataset/pocket/data1/syn/imu1.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/pocket/data1/syn/vi3.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/pocket/data1/syn/vi2.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/pocket/data1/syn/imu2.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/pocket/data1/syn/vi1.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/pocket/data1/syn/imu3.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/pocket/data1/syn/vi5.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/pocket/data1/syn/vi4.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/pocket/data1/syn/imu4.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/pocket/data1/syn/imu5.csv  \n",
            "   creating: data/Oxford Inertial Odometry Dataset/pocket/data1/raw/\n",
            "  inflating: data/Oxford Inertial Odometry Dataset/pocket/data1/raw/imu1.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/pocket/data1/raw/vi3.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/pocket/data1/raw/vi2.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/pocket/data1/raw/imu2.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/pocket/data1/raw/vi1.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/pocket/data1/raw/imu3.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/pocket/data1/raw/vi5.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/pocket/data1/raw/vi4.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/pocket/data1/raw/imu4.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/pocket/data1/raw/imu5.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/pocket/pocket.xlsx  \n",
            " extracting: data/Oxford Inertial Odometry Dataset/pocket/Test.txt  \n",
            "   creating: data/Oxford Inertial Odometry Dataset/pocket/data2/\n",
            "  inflating: data/Oxford Inertial Odometry Dataset/pocket/data2/.DS_Store  \n",
            "   creating: data/Oxford Inertial Odometry Dataset/pocket/data2/syn/\n",
            "  inflating: data/Oxford Inertial Odometry Dataset/pocket/data2/syn/imu1.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/pocket/data2/syn/vi3.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/pocket/data2/syn/vi2.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/pocket/data2/syn/imu2.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/pocket/data2/syn/vi1.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/pocket/data2/syn/imu3.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/pocket/data2/syn/vi5.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/pocket/data2/syn/vi4.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/pocket/data2/syn/imu6.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/pocket/data2/syn/imu4.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/pocket/data2/syn/vi6.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/pocket/data2/syn/imu5.csv  \n",
            "   creating: data/Oxford Inertial Odometry Dataset/pocket/data2/raw/\n",
            "  inflating: data/Oxford Inertial Odometry Dataset/pocket/data2/raw/imu1.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/pocket/data2/raw/vi3.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/pocket/data2/raw/vi2.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/pocket/data2/raw/imu2.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/pocket/data2/raw/vi1.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/pocket/data2/raw/imu3.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/pocket/data2/raw/vi5.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/pocket/data2/raw/vi4.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/pocket/data2/raw/imu6.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/pocket/data2/raw/imu4.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/pocket/data2/raw/vi6.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/pocket/data2/raw/imu5.csv  \n",
            "   creating: data/Oxford Inertial Odometry Dataset/running/\n",
            "  inflating: data/Oxford Inertial Odometry Dataset/running/.DS_Store  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/running/Train.txt  \n",
            "   creating: data/Oxford Inertial Odometry Dataset/running/data1/\n",
            "  inflating: data/Oxford Inertial Odometry Dataset/running/data1/.DS_Store  \n",
            "   creating: data/Oxford Inertial Odometry Dataset/running/data1/syn/\n",
            "  inflating: data/Oxford Inertial Odometry Dataset/running/data1/syn/imu1.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/running/data1/syn/vi3.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/running/data1/syn/vi2.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/running/data1/syn/imu2.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/running/data1/syn/vi1.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/running/data1/syn/imu3.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/running/data1/syn/imu7.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/running/data1/syn/vi5.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/running/data1/syn/vi4.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/running/data1/syn/imu6.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/running/data1/syn/imu4.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/running/data1/syn/vi6.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/running/data1/syn/vi7.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/running/data1/syn/imu5.csv  \n",
            "   creating: data/Oxford Inertial Odometry Dataset/running/data1/raw/\n",
            "  inflating: data/Oxford Inertial Odometry Dataset/running/data1/raw/imu1.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/running/data1/raw/vi3.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/running/data1/raw/vi2.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/running/data1/raw/imu2.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/running/data1/raw/vi1.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/running/data1/raw/imu3.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/running/data1/raw/imu7.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/running/data1/raw/vi5.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/running/data1/raw/vi4.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/running/data1/raw/imu6.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/running/data1/raw/imu4.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/running/data1/raw/vi6.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/running/data1/raw/vi7.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/running/data1/raw/imu5.csv  \n",
            " extracting: data/Oxford Inertial Odometry Dataset/running/Test.txt  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/running/running.xlsx  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/.DS_Store  \n",
            "   creating: data/Oxford Inertial Odometry Dataset/trolley/\n",
            "  inflating: data/Oxford Inertial Odometry Dataset/trolley/trolley.xlsx  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/trolley/.DS_Store  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/trolley/Train.txt  \n",
            "   creating: data/Oxford Inertial Odometry Dataset/trolley/data1/\n",
            "  inflating: data/Oxford Inertial Odometry Dataset/trolley/data1/.DS_Store  \n",
            "   creating: data/Oxford Inertial Odometry Dataset/trolley/data1/syn/\n",
            "  inflating: data/Oxford Inertial Odometry Dataset/trolley/data1/syn/imu1.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/trolley/data1/syn/vi3.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/trolley/data1/syn/vi2.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/trolley/data1/syn/imu2.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/trolley/data1/syn/vi1.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/trolley/data1/syn/imu3.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/trolley/data1/syn/imu7.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/trolley/data1/syn/vi5.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/trolley/data1/syn/vi4.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/trolley/data1/syn/imu6.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/trolley/data1/syn/imu4.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/trolley/data1/syn/vi6.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/trolley/data1/syn/vi7.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/trolley/data1/syn/imu5.csv  \n",
            "   creating: data/Oxford Inertial Odometry Dataset/trolley/data1/raw/\n",
            "  inflating: data/Oxford Inertial Odometry Dataset/trolley/data1/raw/imu1.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/trolley/data1/raw/vi3.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/trolley/data1/raw/vi2.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/trolley/data1/raw/imu2.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/trolley/data1/raw/vi1.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/trolley/data1/raw/imu3.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/trolley/data1/raw/imu7.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/trolley/data1/raw/vi5.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/trolley/data1/raw/vi4.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/trolley/data1/raw/imu6.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/trolley/data1/raw/imu4.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/trolley/data1/raw/vi6.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/trolley/data1/raw/vi7.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/trolley/data1/raw/imu5.csv  \n",
            " extracting: data/Oxford Inertial Odometry Dataset/trolley/Test.txt  \n",
            "   creating: data/Oxford Inertial Odometry Dataset/trolley/data2/\n",
            "  inflating: data/Oxford Inertial Odometry Dataset/trolley/data2/.DS_Store  \n",
            "   creating: data/Oxford Inertial Odometry Dataset/trolley/data2/syn/\n",
            "  inflating: data/Oxford Inertial Odometry Dataset/trolley/data2/syn/imu1.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/trolley/data2/syn/vi3.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/trolley/data2/syn/vi2.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/trolley/data2/syn/imu2.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/trolley/data2/syn/vi1.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/trolley/data2/syn/imu3.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/trolley/data2/syn/vi5.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/trolley/data2/syn/vi4.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/trolley/data2/syn/imu6.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/trolley/data2/syn/imu4.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/trolley/data2/syn/vi6.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/trolley/data2/syn/imu5.csv  \n",
            "   creating: data/Oxford Inertial Odometry Dataset/trolley/data2/raw/\n",
            "  inflating: data/Oxford Inertial Odometry Dataset/trolley/data2/raw/imu1.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/trolley/data2/raw/imu2.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/trolley/data2/raw/imu3.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/trolley/data2/raw/imu6.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/trolley/data2/raw/imu4.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/trolley/data2/raw/imu5.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/trolley/data2/raw/hand1.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/trolley/data2/raw/hand2.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/trolley/data2/raw/hand3.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/trolley/data2/raw/hand6.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/trolley/data2/raw/hand4.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/trolley/data2/raw/hand5.csv  \n",
            "   creating: data/Oxford Inertial Odometry Dataset/test/\n",
            "  inflating: data/Oxford Inertial Odometry Dataset/test/.DS_Store  \n",
            "   creating: data/Oxford Inertial Odometry Dataset/test/large-scale/\n",
            "  inflating: data/Oxford Inertial Odometry Dataset/test/large-scale/.DS_Store  \n",
            "   creating: data/Oxford Inertial Odometry Dataset/test/large-scale/floor2/\n",
            "  inflating: data/Oxford Inertial Odometry Dataset/test/large-scale/floor2/imu1.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/test/large-scale/floor2/.DS_Store  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/test/large-scale/floor2/tango1.csv  \n",
            "   creating: data/Oxford Inertial Odometry Dataset/test/large-scale/floor1/\n",
            "  inflating: data/Oxford Inertial Odometry Dataset/test/large-scale/floor1/imu1.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/test/large-scale/floor1/.DS_Store  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/test/large-scale/floor1/tango1.csv  \n",
            "   creating: data/Oxford Inertial Odometry Dataset/test/multi-attachments/\n",
            "   creating: data/Oxford Inertial Odometry Dataset/test/multi-attachments/pocket/\n",
            "  inflating: data/Oxford Inertial Odometry Dataset/test/multi-attachments/pocket/imu1.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/test/multi-attachments/pocket/vi1.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/test/multi-attachments/pocket/.DS_Store  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/test/multi-attachments/.DS_Store  \n",
            "   creating: data/Oxford Inertial Odometry Dataset/test/multi-attachments/trolley/\n",
            "  inflating: data/Oxford Inertial Odometry Dataset/test/multi-attachments/trolley/imu1.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/test/multi-attachments/trolley/vi1.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/test/multi-attachments/trolley/.DS_Store  \n",
            "   creating: data/Oxford Inertial Odometry Dataset/test/multi-attachments/handbag/\n",
            "  inflating: data/Oxford Inertial Odometry Dataset/test/multi-attachments/handbag/imu1.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/test/multi-attachments/handbag/.DS_Store  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/test/multi-attachments/handbag/hand1.csv  \n",
            "   creating: data/Oxford Inertial Odometry Dataset/test/multi-attachments/handheld/\n",
            "  inflating: data/Oxford Inertial Odometry Dataset/test/multi-attachments/handheld/imu1.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/test/multi-attachments/handheld/vi1.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/test/multi-attachments/handheld/.DS_Store  \n",
            "   creating: data/Oxford Inertial Odometry Dataset/handbag/\n",
            "  inflating: data/Oxford Inertial Odometry Dataset/handbag/.DS_Store  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/handbag/handbag.xlsx  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/handbag/Train.txt  \n",
            "   creating: data/Oxford Inertial Odometry Dataset/handbag/data1/\n",
            "  inflating: data/Oxford Inertial Odometry Dataset/handbag/data1/.DS_Store  \n",
            "   creating: data/Oxford Inertial Odometry Dataset/handbag/data1/syn/\n",
            "  inflating: data/Oxford Inertial Odometry Dataset/handbag/data1/syn/imu1.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/handbag/data1/syn/vi3.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/handbag/data1/syn/vi2.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/handbag/data1/syn/imu2.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/handbag/data1/syn/vi1.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/handbag/data1/syn/imu3.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/handbag/data1/syn/vi4.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/handbag/data1/syn/imu4.csv  \n",
            "   creating: data/Oxford Inertial Odometry Dataset/handbag/data1/raw/\n",
            "  inflating: data/Oxford Inertial Odometry Dataset/handbag/data1/raw/imu1.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/handbag/data1/raw/vi3.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/handbag/data1/raw/vi2.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/handbag/data1/raw/imu2.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/handbag/data1/raw/vi1.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/handbag/data1/raw/imu3.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/handbag/data1/raw/vi4.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/handbag/data1/raw/imu4.csv  \n",
            " extracting: data/Oxford Inertial Odometry Dataset/handbag/Test.txt  \n",
            "   creating: data/Oxford Inertial Odometry Dataset/handbag/data2/\n",
            "  inflating: data/Oxford Inertial Odometry Dataset/handbag/data2/.DS_Store  \n",
            "   creating: data/Oxford Inertial Odometry Dataset/handbag/data2/syn/\n",
            "  inflating: data/Oxford Inertial Odometry Dataset/handbag/data2/syn/imu1.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/handbag/data2/syn/vi3.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/handbag/data2/syn/vi2.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/handbag/data2/syn/imu2.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/handbag/data2/syn/vi1.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/handbag/data2/syn/imu3.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/handbag/data2/syn/vi4.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/handbag/data2/syn/imu4.csv  \n",
            "   creating: data/Oxford Inertial Odometry Dataset/handbag/data2/raw/\n",
            "  inflating: data/Oxford Inertial Odometry Dataset/handbag/data2/raw/imu1.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/handbag/data2/raw/vi3.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/handbag/data2/raw/vi2.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/handbag/data2/raw/imu2.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/handbag/data2/raw/vi1.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/handbag/data2/raw/imu3.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/handbag/data2/raw/vi4.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/handbag/data2/raw/imu4.csv  \n",
            "   creating: data/Oxford Inertial Odometry Dataset/multi users/\n",
            "   creating: data/Oxford Inertial Odometry Dataset/multi users/user2/\n",
            "   creating: data/Oxford Inertial Odometry Dataset/multi users/user2/syn/\n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi users/user2/syn/imu1.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi users/user2/syn/vi3.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi users/user2/syn/vi2.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi users/user2/syn/imu2.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi users/user2/syn/vi1.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi users/user2/syn/imu3.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi users/user2/syn/imu7.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi users/user2/syn/vi5.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi users/user2/syn/vi4.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi users/user2/syn/imu6.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi users/user2/syn/imu4.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi users/user2/syn/vi6.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi users/user2/syn/vi7.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi users/user2/syn/imu5.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi users/user2/syn/imu8.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi users/user2/syn/imu9.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi users/user2/syn/vi9.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi users/user2/syn/vi8.csv  \n",
            "   creating: data/Oxford Inertial Odometry Dataset/multi users/user2/raw/\n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi users/user2/raw/imu1.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi users/user2/raw/vi3.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi users/user2/raw/vi2.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi users/user2/raw/imu2.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi users/user2/raw/vi1.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi users/user2/raw/imu3.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi users/user2/raw/imu7.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi users/user2/raw/vi7.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi users/user2/raw/imu8.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi users/user2/raw/imu9.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi users/user2/raw/vi9.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi users/user2/raw/vi8.csv  \n",
            "   creating: data/Oxford Inertial Odometry Dataset/multi users/user5/\n",
            "   creating: data/Oxford Inertial Odometry Dataset/multi users/user5/syn/\n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi users/user5/syn/imu1.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi users/user5/syn/vi3.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi users/user5/syn/vi2.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi users/user5/syn/imu2.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi users/user5/syn/vi1.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi users/user5/syn/imu3.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi users/user5/syn/imu7.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi users/user5/syn/vi5.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi users/user5/syn/vi4.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi users/user5/syn/imu6.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi users/user5/syn/imu4.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi users/user5/syn/vi6.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi users/user5/syn/vi7.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi users/user5/syn/imu5.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi users/user5/syn/imu10.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi users/user5/syn/vi10.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi users/user5/syn/Readme.txt  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi users/user5/syn/imu8.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi users/user5/syn/imu9.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi users/user5/syn/vi9.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi users/user5/syn/vi8.csv  \n",
            "   creating: data/Oxford Inertial Odometry Dataset/multi users/user5/raw/\n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi users/user5/raw/imu1.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi users/user5/raw/vi3.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi users/user5/raw/vi2.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi users/user5/raw/imu2.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi users/user5/raw/vi1.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi users/user5/raw/imu3.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi users/user5/raw/imu7.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi users/user5/raw/vi5.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi users/user5/raw/vi4.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi users/user5/raw/imu6.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi users/user5/raw/imu4.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi users/user5/raw/vi6.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi users/user5/raw/vi7.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi users/user5/raw/imu5.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi users/user5/raw/imu10.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi users/user5/raw/vi10.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi users/user5/raw/imu8.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi users/user5/raw/imu9.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi users/user5/raw/vi9.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi users/user5/raw/vi8.csv  \n",
            "   creating: data/Oxford Inertial Odometry Dataset/multi users/user4/\n",
            "   creating: data/Oxford Inertial Odometry Dataset/multi users/user4/syn/\n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi users/user4/syn/imu1.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi users/user4/syn/vi3.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi users/user4/syn/vi2.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi users/user4/syn/imu2.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi users/user4/syn/vi1.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi users/user4/syn/imu3.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi users/user4/syn/imu7.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi users/user4/syn/vi5.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi users/user4/syn/vi4.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi users/user4/syn/imu6.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi users/user4/syn/imu4.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi users/user4/syn/vi6.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi users/user4/syn/vi7.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi users/user4/syn/imu5.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi users/user4/syn/imu8.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi users/user4/syn/imu9.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi users/user4/syn/vi9.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi users/user4/syn/vi8.csv  \n",
            "   creating: data/Oxford Inertial Odometry Dataset/multi users/user4/raw/\n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi users/user4/raw/imu1.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi users/user4/raw/vi3.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi users/user4/raw/vi2.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi users/user4/raw/imu2.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi users/user4/raw/vi1.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi users/user4/raw/imu3.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi users/user4/raw/imu7.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi users/user4/raw/vi5.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi users/user4/raw/vi4.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi users/user4/raw/imu6.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi users/user4/raw/imu4.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi users/user4/raw/vi6.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi users/user4/raw/vi7.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi users/user4/raw/imu5.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi users/user4/raw/imu8.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi users/user4/raw/imu9.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi users/user4/raw/vi9.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi users/user4/raw/vi8.csv  \n",
            "   creating: data/Oxford Inertial Odometry Dataset/multi users/user3/\n",
            "   creating: data/Oxford Inertial Odometry Dataset/multi users/user3/syn/\n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi users/user3/syn/imu1.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi users/user3/syn/vi3.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi users/user3/syn/vi2.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi users/user3/syn/imu2.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi users/user3/syn/vi1.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi users/user3/syn/imu3.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi users/user3/syn/imu7.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi users/user3/syn/vi5.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi users/user3/syn/vi4.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi users/user3/syn/imu6.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi users/user3/syn/imu4.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi users/user3/syn/vi6.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi users/user3/syn/vi7.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi users/user3/syn/imu5.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi users/user3/syn/Readme.txt  \n",
            "   creating: data/Oxford Inertial Odometry Dataset/multi users/user3/raw/\n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi users/user3/raw/imu1.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi users/user3/raw/vi3.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi users/user3/raw/vi2.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi users/user3/raw/imu2.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi users/user3/raw/vi1.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi users/user3/raw/imu3.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi users/user3/raw/vi5.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi users/user3/raw/vi4.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi users/user3/raw/imu6.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi users/user3/raw/imu4.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi users/user3/raw/vi6.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi users/user3/raw/imu5.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/multi users/multi users.xlsx  \n",
            "   creating: data/Oxford Inertial Odometry Dataset/slow walking/\n",
            "  inflating: data/Oxford Inertial Odometry Dataset/slow walking/.DS_Store  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/slow walking/Train.txt  \n",
            "   creating: data/Oxford Inertial Odometry Dataset/slow walking/data1/\n",
            "  inflating: data/Oxford Inertial Odometry Dataset/slow walking/data1/.DS_Store  \n",
            "   creating: data/Oxford Inertial Odometry Dataset/slow walking/data1/syn/\n",
            "  inflating: data/Oxford Inertial Odometry Dataset/slow walking/data1/syn/imu1.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/slow walking/data1/syn/vi3.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/slow walking/data1/syn/vi2.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/slow walking/data1/syn/imu2.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/slow walking/data1/syn/vi1.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/slow walking/data1/syn/imu3.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/slow walking/data1/syn/imu7.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/slow walking/data1/syn/vi5.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/slow walking/data1/syn/vi4.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/slow walking/data1/syn/imu6.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/slow walking/data1/syn/imu4.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/slow walking/data1/syn/vi6.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/slow walking/data1/syn/vi7.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/slow walking/data1/syn/imu5.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/slow walking/data1/syn/imu8.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/slow walking/data1/syn/vi8.csv  \n",
            "   creating: data/Oxford Inertial Odometry Dataset/slow walking/data1/raw/\n",
            "  inflating: data/Oxford Inertial Odometry Dataset/slow walking/data1/raw/imu1.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/slow walking/data1/raw/vi3.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/slow walking/data1/raw/vi2.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/slow walking/data1/raw/imu2.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/slow walking/data1/raw/vi1.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/slow walking/data1/raw/imu3.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/slow walking/data1/raw/imu7.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/slow walking/data1/raw/vi5.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/slow walking/data1/raw/vi4.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/slow walking/data1/raw/imu6.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/slow walking/data1/raw/imu4.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/slow walking/data1/raw/vi6.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/slow walking/data1/raw/vi7.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/slow walking/data1/raw/imu5.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/slow walking/data1/raw/imu8.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/slow walking/data1/raw/vi8.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/slow walking/slow walking.xlsx  \n",
            " extracting: data/Oxford Inertial Odometry Dataset/slow walking/Test.txt  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/ReadMe.txt  \n",
            "   creating: data/Oxford Inertial Odometry Dataset/handheld/\n",
            "  inflating: data/Oxford Inertial Odometry Dataset/handheld/handheld.xlsx  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/handheld/.DS_Store  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/handheld/Train.txt  \n",
            "   creating: data/Oxford Inertial Odometry Dataset/handheld/data1/\n",
            "  inflating: data/Oxford Inertial Odometry Dataset/handheld/data1/.DS_Store  \n",
            "   creating: data/Oxford Inertial Odometry Dataset/handheld/data1/syn/\n",
            "  inflating: data/Oxford Inertial Odometry Dataset/handheld/data1/syn/imu1.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/handheld/data1/syn/vi3.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/handheld/data1/syn/vi2.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/handheld/data1/syn/imu2.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/handheld/data1/syn/vi1.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/handheld/data1/syn/imu3.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/handheld/data1/syn/imu7.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/handheld/data1/syn/vi5.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/handheld/data1/syn/vi4.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/handheld/data1/syn/imu6.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/handheld/data1/syn/imu4.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/handheld/data1/syn/vi6.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/handheld/data1/syn/vi7.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/handheld/data1/syn/imu5.csv  \n",
            "   creating: data/Oxford Inertial Odometry Dataset/handheld/data1/raw/\n",
            "  inflating: data/Oxford Inertial Odometry Dataset/handheld/data1/raw/imu1.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/handheld/data1/raw/vi3.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/handheld/data1/raw/vi2.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/handheld/data1/raw/imu2.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/handheld/data1/raw/vi1.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/handheld/data1/raw/imu3.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/handheld/data1/raw/imu7.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/handheld/data1/raw/vi5.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/handheld/data1/raw/vi4.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/handheld/data1/raw/imu6.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/handheld/data1/raw/imu4.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/handheld/data1/raw/vi6.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/handheld/data1/raw/vi7.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/handheld/data1/raw/imu5.csv  \n",
            " extracting: data/Oxford Inertial Odometry Dataset/handheld/Test.txt  \n",
            "   creating: data/Oxford Inertial Odometry Dataset/handheld/data2/\n",
            "  inflating: data/Oxford Inertial Odometry Dataset/handheld/data2/.DS_Store  \n",
            "   creating: data/Oxford Inertial Odometry Dataset/handheld/data2/syn/\n",
            "  inflating: data/Oxford Inertial Odometry Dataset/handheld/data2/syn/imu1.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/handheld/data2/syn/vi3.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/handheld/data2/syn/vi2.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/handheld/data2/syn/imu2.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/handheld/data2/syn/vi1.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/handheld/data2/syn/imu3.csv  \n",
            "   creating: data/Oxford Inertial Odometry Dataset/handheld/data2/raw/\n",
            "  inflating: data/Oxford Inertial Odometry Dataset/handheld/data2/raw/imu1.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/handheld/data2/raw/vi3.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/handheld/data2/raw/vi2.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/handheld/data2/raw/imu2.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/handheld/data2/raw/vi1.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/handheld/data2/raw/imu3.csv  \n",
            "   creating: data/Oxford Inertial Odometry Dataset/handheld/data3/\n",
            "  inflating: data/Oxford Inertial Odometry Dataset/handheld/data3/.DS_Store  \n",
            "   creating: data/Oxford Inertial Odometry Dataset/handheld/data3/syn/\n",
            "  inflating: data/Oxford Inertial Odometry Dataset/handheld/data3/syn/imu1.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/handheld/data3/syn/vi3.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/handheld/data3/syn/vi2.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/handheld/data3/syn/imu2.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/handheld/data3/syn/vi1.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/handheld/data3/syn/imu3.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/handheld/data3/syn/vi5.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/handheld/data3/syn/vi4.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/handheld/data3/syn/imu4.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/handheld/data3/syn/imu5.csv  \n",
            "   creating: data/Oxford Inertial Odometry Dataset/handheld/data3/raw/\n",
            "  inflating: data/Oxford Inertial Odometry Dataset/handheld/data3/raw/imu1.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/handheld/data3/raw/vi3.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/handheld/data3/raw/vi2.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/handheld/data3/raw/imu2.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/handheld/data3/raw/vi1.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/handheld/data3/raw/imu3.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/handheld/data3/raw/vi5.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/handheld/data3/raw/vi4.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/handheld/data3/raw/imu4.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/handheld/data3/raw/imu5.csv  \n",
            "   creating: data/Oxford Inertial Odometry Dataset/handheld/data4/\n",
            "  inflating: data/Oxford Inertial Odometry Dataset/handheld/data4/.DS_Store  \n",
            "   creating: data/Oxford Inertial Odometry Dataset/handheld/data4/syn/\n",
            "  inflating: data/Oxford Inertial Odometry Dataset/handheld/data4/syn/imu1.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/handheld/data4/syn/vi3.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/handheld/data4/syn/vi2.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/handheld/data4/syn/imu2.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/handheld/data4/syn/vi1.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/handheld/data4/syn/imu3.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/handheld/data4/syn/vi5.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/handheld/data4/syn/vi4.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/handheld/data4/syn/imu4.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/handheld/data4/syn/imu5.csv  \n",
            "   creating: data/Oxford Inertial Odometry Dataset/handheld/data4/raw/\n",
            "  inflating: data/Oxford Inertial Odometry Dataset/handheld/data4/raw/imu1.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/handheld/data4/raw/vi3.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/handheld/data4/raw/vi2.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/handheld/data4/raw/imu2.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/handheld/data4/raw/vi1.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/handheld/data4/raw/imu3.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/handheld/data4/raw/vi5.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/handheld/data4/raw/vi4.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/handheld/data4/raw/imu4.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/handheld/data4/raw/imu5.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/total.xlsx  \n",
            "replace data/Oxford Inertial Odometry Dataset/.gitkeep? [y]es, [n]o, [A]ll, [N]one, [r]ename:  extracting: data/Oxford Inertial Odometry Dataset/.gitkeep  \n",
            "   creating: data/Oxford Inertial Odometry Dataset/handheld_test/\n",
            "  inflating: data/Oxford Inertial Odometry Dataset/handheld_test/.DS_Store  \n",
            " extracting: data/Oxford Inertial Odometry Dataset/handheld_test/Test.txt  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/handheld_test/Train.txt  \n",
            "   creating: data/Oxford Inertial Odometry Dataset/handheld_test/data5/\n",
            "  inflating: data/Oxford Inertial Odometry Dataset/handheld_test/data5/.DS_Store  \n",
            "   creating: data/Oxford Inertial Odometry Dataset/handheld_test/data5/raw/\n",
            "  inflating: data/Oxford Inertial Odometry Dataset/handheld_test/data5/raw/imu1.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/handheld_test/data5/raw/imu2.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/handheld_test/data5/raw/imu3.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/handheld_test/data5/raw/imu4.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/handheld_test/data5/raw/vi1.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/handheld_test/data5/raw/vi2.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/handheld_test/data5/raw/vi3.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/handheld_test/data5/raw/vi4.csv  \n",
            "   creating: data/Oxford Inertial Odometry Dataset/handheld_test/data5/syn/\n",
            "  inflating: data/Oxford Inertial Odometry Dataset/handheld_test/data5/syn/imu1.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/handheld_test/data5/syn/imu2.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/handheld_test/data5/syn/imu3.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/handheld_test/data5/syn/imu4.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/handheld_test/data5/syn/vi1.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/handheld_test/data5/syn/vi2.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/handheld_test/data5/syn/vi3.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/handheld_test/data5/syn/vi4.csv  \n",
            "  inflating: data/Oxford Inertial Odometry Dataset/handheld_test/handheld.xlsx  \n"
          ]
        }
      ],
      "source": [
        "!yes|unzip data.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b_BkVzdu4utc"
      },
      "source": [
        "# **Run LSTM**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vpJZKKhk31t5",
        "outputId": "e3462d45-7154-4072-d6d4-048dcdf013bd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Errno 2] No such file or directory: 'src'\n",
            "/content\n",
            "[Errno 2] No such file or directory: 'easy_lstm'\n",
            "/content\n",
            "indoor_localization_oxford_dataset  sample_data\n"
          ]
        }
      ],
      "source": [
        "%cd /\n",
        "!ls\n",
        "%cd content\n",
        "%cd indoor_localization_oxford_dataset\n",
        "%cd src\n",
        "%cd easy_lstm\n",
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0kwasRkW3Kxq",
        "outputId": "5cf6e011-ad4f-4e6c-cc37-ff3f875d811c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total training samples: 6058\n",
            "Total validation samples: 925\n",
            "Total samples: 6983\n",
            "Input shape: torch.Size([100, 15])\n",
            "Target shape: torch.Size([3])\n",
            "Number of training batches: 190\n",
            "Number of validation batches: 29\n",
            "Using device: cuda\n",
            "Performing mean baseline evaluation...\n",
            "Baseline Train Loss: 1.5235, Baseline Val Loss: 1.5011\n",
            "Epoch [1/50], Train Loss: 1.1523, Val Loss: 0.8554\n",
            "Epoch [2/50], Train Loss: 0.7949, Val Loss: 0.6841\n",
            "Epoch [3/50], Train Loss: 0.6957, Val Loss: 0.7081\n",
            "Epoch [4/50], Train Loss: 0.6160, Val Loss: 0.6879\n",
            "Epoch [5/50], Train Loss: 0.5437, Val Loss: 0.5840\n",
            "Epoch [6/50], Train Loss: 0.5134, Val Loss: 0.5842\n",
            "Epoch [7/50], Train Loss: 0.4819, Val Loss: 0.5724\n",
            "Epoch [8/50], Train Loss: 0.4558, Val Loss: 0.6158\n",
            "Epoch [9/50], Train Loss: 0.4421, Val Loss: 0.5752\n",
            "Epoch [10/50], Train Loss: 0.4296, Val Loss: 0.5518\n",
            "Epoch [11/50], Train Loss: 0.4107, Val Loss: 0.6321\n",
            "Epoch [12/50], Train Loss: 0.3981, Val Loss: 0.5954\n",
            "Epoch [13/50], Train Loss: 0.3823, Val Loss: 0.4986\n",
            "Epoch [14/50], Train Loss: 0.3793, Val Loss: 0.5198\n",
            "Epoch [15/50], Train Loss: 0.3622, Val Loss: 0.5540\n",
            "Epoch [16/50], Train Loss: 0.3676, Val Loss: 0.5761\n",
            "Epoch [17/50], Train Loss: 0.3712, Val Loss: 0.5558\n",
            "Epoch [18/50], Train Loss: 0.3541, Val Loss: 0.5838\n",
            "Epoch [19/50], Train Loss: 0.3472, Val Loss: 0.5807\n",
            "Epoch [20/50], Train Loss: 0.3483, Val Loss: 0.5275\n",
            "Epoch [21/50], Train Loss: 0.3356, Val Loss: 0.5285\n",
            "Epoch [22/50], Train Loss: 0.3261, Val Loss: 0.5080\n",
            "Epoch [23/50], Train Loss: 0.3223, Val Loss: 0.5607\n",
            "Epoch [24/50], Train Loss: 0.3331, Val Loss: 0.5218\n",
            "Epoch [25/50], Train Loss: 0.3164, Val Loss: 0.5416\n",
            "Epoch [26/50], Train Loss: 0.3102, Val Loss: 0.5079\n",
            "Epoch [27/50], Train Loss: 0.3043, Val Loss: 0.5552\n",
            "Epoch [28/50], Train Loss: 0.2968, Val Loss: 0.5181\n",
            "Epoch [29/50], Train Loss: 0.2985, Val Loss: 0.5275\n",
            "Epoch [30/50], Train Loss: 0.2949, Val Loss: 0.5460\n",
            "Epoch [31/50], Train Loss: 0.3271, Val Loss: 0.5047\n",
            "Epoch [32/50], Train Loss: 0.2986, Val Loss: 0.5218\n",
            "Epoch [33/50], Train Loss: 0.3011, Val Loss: 0.5766\n",
            "Epoch [34/50], Train Loss: 0.2902, Val Loss: 0.5212\n",
            "Epoch [35/50], Train Loss: 0.2805, Val Loss: 0.5485\n",
            "Epoch [36/50], Train Loss: 0.2897, Val Loss: 0.5737\n",
            "Epoch [37/50], Train Loss: 0.2855, Val Loss: 0.5143\n",
            "Epoch [38/50], Train Loss: 0.3087, Val Loss: 0.4817\n",
            "Epoch [39/50], Train Loss: 0.2920, Val Loss: 0.5213\n",
            "Epoch [40/50], Train Loss: 0.2868, Val Loss: 0.5213\n",
            "Epoch [41/50], Train Loss: 0.2758, Val Loss: 0.5349\n",
            "Epoch [42/50], Train Loss: 0.2679, Val Loss: 0.5212\n",
            "Epoch [43/50], Train Loss: 0.2673, Val Loss: 0.5456\n",
            "Epoch [44/50], Train Loss: 0.2718, Val Loss: 0.5342\n",
            "Epoch [45/50], Train Loss: 0.2602, Val Loss: 0.5006\n",
            "Epoch [46/50], Train Loss: 0.2655, Val Loss: 0.5807\n",
            "Epoch [47/50], Train Loss: 0.2578, Val Loss: 0.5457\n",
            "Epoch [48/50], Train Loss: 0.2550, Val Loss: 0.5510\n",
            "Epoch [49/50], Train Loss: 0.2622, Val Loss: 0.5988\n",
            "Epoch [50/50], Train Loss: 0.2696, Val Loss: 0.5085\n",
            "Training completed.\n",
            "\n",
            "Starting model evaluation...\n",
            "\n",
            "Starting model evaluation...\n",
            "Testing Dataset Information:\n",
            "Number of sequences: 4\n",
            "Model Sequence length: 100\n",
            "Evaluating:   0% 0/4 [00:00<?, ?it/s]\n",
            "Sequence: data5/imu1.csv\n",
            "MAE: 0.5016\n",
            "MSE: 0.6631\n",
            "Evaluating:  25% 1/4 [00:33<01:41, 33.68s/it]\n",
            "Sequence: data5/imu2.csv\n",
            "MAE: 0.4227\n",
            "MSE: 0.5142\n",
            "Evaluating:  50% 2/4 [01:38<01:44, 52.09s/it]\n",
            "Sequence: data5/imu3.csv\n",
            "MAE: 0.4462\n",
            "MSE: 0.5633\n",
            "Evaluating:  75% 3/4 [02:39<00:56, 56.18s/it]"
          ]
        }
      ],
      "source": [
        "# Basic configuration:\n",
        "!python lstm_train.py --sequence_length 100 --hidden_sizes 64 32 --num_epochs 50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wLguO4fR3QFc",
        "outputId": "329f7e33-72e4-4661-f6a0-a75cf0b64710"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total training samples: 3025\n",
            "Total validation samples: 462\n",
            "Total samples: 3487\n",
            "Input shape: torch.Size([200, 15])\n",
            "Target shape: torch.Size([3])\n",
            "Number of training batches: 95\n",
            "Number of validation batches: 15\n",
            "Using device: cuda\n",
            "Performing mean baseline evaluation...\n",
            "Baseline Train Loss: 1.5231, Baseline Val Loss: 1.5008\n",
            "Epoch [1/80], Train Loss: 1.5125, Val Loss: 1.1345\n",
            "Epoch [2/80], Train Loss: 1.0415, Val Loss: 0.7708\n",
            "Epoch [3/80], Train Loss: 0.7730, Val Loss: 0.6864\n",
            "Epoch [4/80], Train Loss: 0.7207, Val Loss: 0.6911\n",
            "Epoch [5/80], Train Loss: 0.6268, Val Loss: 0.6137\n",
            "Epoch [6/80], Train Loss: 0.5494, Val Loss: 0.6086\n",
            "Epoch [7/80], Train Loss: 0.5667, Val Loss: 0.6792\n",
            "Epoch [8/80], Train Loss: 0.5647, Val Loss: 0.4994\n",
            "Epoch [9/80], Train Loss: 0.5136, Val Loss: 0.5543\n",
            "Epoch [10/80], Train Loss: 0.4917, Val Loss: 0.5632\n",
            "Epoch [11/80], Train Loss: 0.5466, Val Loss: 0.6251\n",
            "Epoch [12/80], Train Loss: 0.4659, Val Loss: 0.4584\n",
            "Epoch [13/80], Train Loss: 0.7039, Val Loss: 0.5337\n",
            "Epoch [14/80], Train Loss: 0.4920, Val Loss: 0.4830\n",
            "Epoch [15/80], Train Loss: 0.4485, Val Loss: 0.4912\n",
            "Epoch [16/80], Train Loss: 0.4205, Val Loss: 0.5092\n",
            "Epoch [17/80], Train Loss: 0.4215, Val Loss: 0.4711\n",
            "Epoch [18/80], Train Loss: 0.4160, Val Loss: 0.4726\n",
            "Epoch [19/80], Train Loss: 0.3868, Val Loss: 0.4787\n",
            "Epoch [20/80], Train Loss: 0.3868, Val Loss: 0.4120\n",
            "Epoch [21/80], Train Loss: 0.3821, Val Loss: 0.4807\n",
            "Epoch [22/80], Train Loss: 0.3646, Val Loss: 0.5098\n",
            "Epoch [23/80], Train Loss: 0.3868, Val Loss: 0.4528\n",
            "Epoch [24/80], Train Loss: 0.3666, Val Loss: 0.4386\n",
            "Epoch [25/80], Train Loss: 0.3628, Val Loss: 0.4238\n",
            "Epoch [26/80], Train Loss: 0.3384, Val Loss: 0.5033\n",
            "Epoch [27/80], Train Loss: 0.3322, Val Loss: 0.4708\n",
            "Epoch [28/80], Train Loss: 0.3237, Val Loss: 0.4327\n",
            "Epoch [29/80], Train Loss: 0.3301, Val Loss: 0.4661\n",
            "Epoch [30/80], Train Loss: 0.3228, Val Loss: 0.4433\n",
            "Epoch [31/80], Train Loss: 0.3376, Val Loss: 0.4405\n",
            "Epoch [32/80], Train Loss: 0.3138, Val Loss: 0.5026\n",
            "Epoch [33/80], Train Loss: 0.3232, Val Loss: 0.4188\n",
            "Epoch [34/80], Train Loss: 0.3155, Val Loss: 0.5286\n",
            "Epoch [35/80], Train Loss: 0.3734, Val Loss: 0.4508\n",
            "Epoch [36/80], Train Loss: 0.3630, Val Loss: 0.4460\n",
            "Epoch [37/80], Train Loss: 0.3508, Val Loss: 0.4581\n",
            "Epoch [38/80], Train Loss: 0.3185, Val Loss: 0.4496\n",
            "Epoch [39/80], Train Loss: 0.3358, Val Loss: 0.4688\n",
            "Epoch [40/80], Train Loss: 0.3332, Val Loss: 0.4314\n",
            "Epoch [41/80], Train Loss: 0.3075, Val Loss: 0.4507\n",
            "Epoch [42/80], Train Loss: 0.3141, Val Loss: 0.4874\n",
            "Epoch [43/80], Train Loss: 0.3088, Val Loss: 0.4937\n",
            "Epoch [44/80], Train Loss: 0.2906, Val Loss: 0.4225\n",
            "Epoch [45/80], Train Loss: 0.2751, Val Loss: 0.3849\n",
            "Epoch [46/80], Train Loss: 0.2806, Val Loss: 0.4217\n",
            "Epoch [47/80], Train Loss: 0.2955, Val Loss: 0.4130\n",
            "Epoch [48/80], Train Loss: 0.2635, Val Loss: 0.4432\n",
            "Epoch [49/80], Train Loss: 0.2690, Val Loss: 0.4334\n",
            "Epoch [50/80], Train Loss: 0.2664, Val Loss: 0.3828\n",
            "Epoch [51/80], Train Loss: 0.3021, Val Loss: 0.4479\n",
            "Epoch [52/80], Train Loss: 0.2920, Val Loss: 0.3635\n",
            "Epoch [53/80], Train Loss: 0.2551, Val Loss: 0.3938\n",
            "Epoch [54/80], Train Loss: 0.2522, Val Loss: 0.4185\n",
            "Epoch [55/80], Train Loss: 0.2449, Val Loss: 0.3689\n",
            "Epoch [56/80], Train Loss: 0.2581, Val Loss: 0.4670\n",
            "Epoch [57/80], Train Loss: 0.2419, Val Loss: 0.4197\n",
            "Epoch [58/80], Train Loss: 0.2518, Val Loss: 0.4085\n",
            "Epoch [59/80], Train Loss: 0.2396, Val Loss: 0.4330\n",
            "Epoch [60/80], Train Loss: 0.2300, Val Loss: 0.3978\n",
            "Epoch [61/80], Train Loss: 0.2312, Val Loss: 0.4116\n",
            "Epoch [62/80], Train Loss: 0.2366, Val Loss: 0.3910\n",
            "Epoch [63/80], Train Loss: 0.2516, Val Loss: 0.4359\n",
            "Epoch [64/80], Train Loss: 0.2430, Val Loss: 0.4074\n",
            "Epoch [65/80], Train Loss: 0.2602, Val Loss: 0.3928\n",
            "Epoch [66/80], Train Loss: 0.3018, Val Loss: 0.4210\n",
            "Epoch [67/80], Train Loss: 0.2497, Val Loss: 0.3947\n",
            "Epoch [68/80], Train Loss: 0.2323, Val Loss: 0.4303\n",
            "Epoch [69/80], Train Loss: 0.2205, Val Loss: 0.4073\n",
            "Epoch [70/80], Train Loss: 0.2773, Val Loss: 0.4403\n",
            "Epoch [71/80], Train Loss: 0.2473, Val Loss: 0.3870\n",
            "Epoch [72/80], Train Loss: 0.2318, Val Loss: 0.3851\n",
            "Epoch [73/80], Train Loss: 0.2181, Val Loss: 0.3777\n",
            "Epoch [74/80], Train Loss: 0.2304, Val Loss: 0.3788\n",
            "Epoch [75/80], Train Loss: 0.2443, Val Loss: 0.3847\n",
            "Epoch [76/80], Train Loss: 0.2802, Val Loss: 0.4285\n",
            "Epoch [77/80], Train Loss: 0.2668, Val Loss: 0.3746\n",
            "Epoch [78/80], Train Loss: 0.2305, Val Loss: 0.3821\n",
            "Epoch [79/80], Train Loss: 0.2233, Val Loss: 0.4228\n",
            "Epoch [80/80], Train Loss: 0.2695, Val Loss: 0.3884\n",
            "Training completed.\n",
            "\n",
            "Starting model evaluation...\n",
            "\n",
            "Starting model evaluation...\n",
            "Testing Dataset Information:\n",
            "Number of sequences: 4\n",
            "Model Sequence length: 200\n",
            "Evaluating:   0% 0/4 [00:00<?, ?it/s]\n",
            "Sequence: data5/imu1.csv\n",
            "MAE: 0.4389\n",
            "MSE: 0.4969\n",
            "Evaluating:  25% 1/4 [00:28<01:24, 28.16s/it]\n",
            "Sequence: data5/imu2.csv\n",
            "MAE: 0.3539\n",
            "MSE: 0.3432\n",
            "Evaluating:  50% 2/4 [01:22<01:27, 43.76s/it]\n",
            "Sequence: data5/imu3.csv\n",
            "MAE: 0.3578\n",
            "MSE: 0.3351\n",
            "Evaluating:  75% 3/4 [02:14<00:47, 47.35s/it]\n",
            "Sequence: data5/imu4.csv\n",
            "MAE: 0.3345\n",
            "MSE: 0.3019\n",
            "Evaluating: 100% 4/4 [02:47<00:00, 41.94s/it]\n",
            "\n",
            "Overall Test Loss: 0.3585\n",
            "Predictions shape: (183042, 3)\n",
            "Targets shape: (183042, 3)\n",
            "\n",
            "Overall Mean Squared Error: 0.3585\n",
            "Overall Mean Absolute Error: 0.3656\n",
            "Test results logged to TensorBoard in ../../logs/20240808-213034_input15_hidden64_output3_lr0.001_batch32_dropout0.4_sequencelength200\n"
          ]
        }
      ],
      "source": [
        "# A Very Good Configuration(according to previous finetuning)\n",
        "!python lstm_train.py --sequence_length 200 --hidden_sizes 64 --num_epochs 80 --dropout_rate 0.4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7RhSD_lMuGoj"
      },
      "outputs": [],
      "source": [
        "# Longer sequence length\n",
        "!python lstm_train.py --sequence_length 200 --hidden_sizes 64 32 --num_epochs 50\n",
        "# Shorter sequence length\n",
        "!python lstm_train.py --sequence_length 50 --hidden_sizes 64 32 --num_epochs 50\n",
        "# Single layer LSTM\n",
        "!python lstm_train.py --sequence_length 100 --hidden_sizes 128 --num_epochs 50\n",
        "# Three-layer LSTM\n",
        "!python lstm_train.py --sequence_length 100 --hidden_sizes 64 32 16 --num_epochs 50\n",
        "# Larger hidden sizes\n",
        "!python lstm_train.py --sequence_length 100 --hidden_sizes 128 64 --num_epochs 50\n",
        "# Smaller hidden sizes\n",
        "!python lstm_train.py --sequence_length 100 --hidden_sizes 32 16 --num_epochs 50\n",
        "# Complex configuration\n",
        "!python lstm_train.py --sequence_length 300 --hidden_sizes 128 64 32 16 --num_epochs 75\n",
        "###### With higher dropout #####\n",
        "# Longer sequence length\n",
        "!python lstm_train.py --sequence_length 200 --hidden_sizes 64 32 --num_epochs 50 --dropout_rate 0.5\n",
        "\n",
        "# Single layer LSTM\n",
        "!python lstm_train.py --sequence_length 200 --hidden_sizes 64 --num_epochs 50 --dropout_rate 0.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LiNslOD82kM7"
      },
      "outputs": [],
      "source": [
        "!python lstm_train.py --sequence_length 200 --hidden_sizes 32 --num_epochs 80 --dropout_rate 0.5\n",
        "!python lstm_train.py --sequence_length 200 --hidden_sizes 32 --num_epochs 50 --dropout 0.2\n",
        "# Large Batch\n",
        "!python lstm_train.py --sequence_length 200 --hidden_sizes 32 --num_epochs 100 --batch_size 128 --dropout_rate 0.2\n",
        "!python lstm_train.py --sequence_length 200 --hidden_sizes 32 --num_epochs 100 --batch_size 128 --dropout_rate 0.4\n",
        "# Large Hidden Size\n",
        "!python lstm_train.py --sequence_length 200 --hidden_sizes 64 --num_epochs 50 --dropout_rate 0.2\n",
        "\n",
        "# Run it twice\n",
        "!python lstm_train.py --sequence_length 200 --hidden_sizes 64 --num_epochs 80 --dropout_rate 0.4\n",
        "!python lstm_train.py --sequence_length 200 --hidden_sizes 64 --num_epochs 80 --dropout_rate 0.4\n",
        "\n",
        "!python lstm_train.py --sequence_length 200 --hidden_sizes 256 --num_epochs 50 --dropout_rate 0.4\n",
        "\n",
        "# More Runs\n",
        "!python lstm_train.py --sequence_length 200 --hidden_sizes 64 --num_epochs 60 --dropout_rate 0.3\n",
        "!python lstm_train.py --sequence_length 200 --hidden_sizes 96 --num_epochs 80 --dropout_rate 0.4\n",
        "!python lstm_train.py --sequence_length 200 --hidden_sizes 128 64 --num_epochs 75 --dropout_rate 0.4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6j_7icaA4qFr"
      },
      "source": [
        "# **Run Transformer**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-56wRN4V4nIi",
        "outputId": "3e414b6a-b776-4f11-e17f-0d761b723446"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/\n",
            "bin\t\t\t    datalab  kaggle  libx32\t\t       opt\t   run\t tmp\n",
            "boot\t\t\t    dev      lib     media\t\t       proc\t   sbin  tools\n",
            "content\t\t\t    etc      lib32   mnt\t\t       python-apt  srv\t usr\n",
            "cuda-keyring_1.0-1_all.deb  home     lib64   NGC-DL-CONTAINER-LICENSE  root\t   sys\t var\n",
            "/content\n",
            "/content/indoor_localization_oxford_dataset\n",
            "/content/indoor_localization_oxford_dataset/src\n",
            "/content/indoor_localization_oxford_dataset/src/easy_transformer\n",
            "data_preprocessing.py  README.md\t     transformer_test.py\n",
            "__pycache__\t       transformer_model.py  transformer_train.py\n"
          ]
        }
      ],
      "source": [
        "%cd /\n",
        "!ls\n",
        "%cd content\n",
        "%cd indoor_localization_oxford_dataset\n",
        "%cd src\n",
        "%cd easy_transformer\n",
        "!ls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Dummy Run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8iIf7sD67P-t",
        "outputId": "181faf38-9265-4916-db25-6e8c949ad17e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n",
            "Total training samples: 3025\n",
            "Total validation samples: 462\n",
            "Total samples: 3487\n",
            "Input shape: torch.Size([200, 15])\n",
            "Target shape: torch.Size([3])\n",
            "Number of training batches: 95\n",
            "Number of validation batches: 15\n",
            "Performing mean baseline evaluation...\n",
            "Baseline Train Loss: 1.5231, Baseline Val Loss: 1.5008\n",
            "Epoch [1/10], Train Loss: 1.3448, Val Loss: 0.8849\n",
            "Epoch [2/10], Train Loss: 0.7648, Val Loss: 0.6261\n",
            "Epoch [3/10], Train Loss: 0.6330, Val Loss: 0.6222\n",
            "Epoch [4/10], Train Loss: 0.5978, Val Loss: 0.5929\n",
            "Epoch [5/10], Train Loss: 0.5547, Val Loss: 0.5423\n",
            "Epoch [6/10], Train Loss: 0.5329, Val Loss: 0.4946\n",
            "Epoch [7/10], Train Loss: 0.5053, Val Loss: 0.4718\n",
            "Epoch [8/10], Train Loss: 0.4857, Val Loss: 0.4412\n",
            "Epoch [9/10], Train Loss: 0.4536, Val Loss: 0.4764\n",
            "Epoch [10/10], Train Loss: 0.4367, Val Loss: 0.4285\n",
            "Training completed.\n",
            "\n",
            "Starting model evaluation...\n",
            "\n",
            "Starting model evaluation...\n",
            "Testing Dataset Information:\n",
            "Number of sequences: 4\n",
            "Model Sequence length: 200\n",
            "Evaluating:   0% 0/4 [00:00<?, ?it/s]\n",
            "Sequence: data5/imu1.csv\n",
            "MAE: 0.4693\n",
            "MSE: 0.5721\n",
            "Evaluating:  25% 1/4 [00:30<01:31, 30.52s/it]\n",
            "Sequence: data5/imu2.csv\n",
            "MAE: 0.4120\n",
            "MSE: 0.4431\n",
            "Evaluating:  50% 2/4 [01:28<01:33, 46.71s/it]\n",
            "Sequence: data5/imu3.csv\n",
            "MAE: 0.4153\n",
            "MSE: 0.4186\n",
            "Evaluating:  75% 3/4 [02:23<00:50, 50.45s/it]\n",
            "Sequence: data5/imu4.csv\n",
            "MAE: 0.4050\n",
            "MSE: 0.3915\n",
            "Evaluating: 100% 4/4 [02:59<00:00, 44.78s/it]\n",
            "\n",
            "Overall Test Loss: 0.4472\n",
            "Predictions shape: (183042, 3)\n",
            "Targets shape: (183042, 3)\n",
            "\n",
            "Overall Mean Squared Error: 0.4472\n",
            "Overall Mean Absolute Error: 0.4213\n",
            "Test results logged to TensorBoard in ../../transformer_logs/20240808-214254_d_model64_nhead2_layers1_ff256_output3_batch32_dropout0.2_sequencelength200_poolinglast_returnallFalse\n"
          ]
        }
      ],
      "source": [
        "!python transformer_train.py --num_epochs 10\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DHVMcqGK5K05",
        "outputId": "5c4cf3d0-b138-4027-f490-45911afde063"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n",
            "Total training samples: 3025\n",
            "Total validation samples: 462\n",
            "Total samples: 3487\n",
            "Input shape: torch.Size([200, 15])\n",
            "Target shape: torch.Size([3])\n",
            "Number of training batches: 48\n",
            "Number of validation batches: 8\n",
            "Performing mean baseline evaluation...\n",
            "Baseline Train Loss: 1.5231, Baseline Val Loss: 1.5008\n",
            "Epoch [1/50], Train Loss: 1.7301, Val Loss: 0.8286\n",
            "Epoch [2/50], Train Loss: 1.1172, Val Loss: 0.7336\n",
            "Epoch [3/50], Train Loss: 0.8988, Val Loss: 0.6506\n",
            "Epoch [4/50], Train Loss: 0.7637, Val Loss: 0.5632\n",
            "Epoch [5/50], Train Loss: 0.6940, Val Loss: 0.5449\n",
            "Epoch [6/50], Train Loss: 0.6463, Val Loss: 0.5182\n",
            "Epoch [7/50], Train Loss: 0.6272, Val Loss: 0.5443\n",
            "Epoch [8/50], Train Loss: 0.6088, Val Loss: 0.5322\n",
            "Epoch [9/50], Train Loss: 0.5788, Val Loss: 0.5008\n",
            "Epoch [10/50], Train Loss: 0.5651, Val Loss: 0.4789\n",
            "Epoch [11/50], Train Loss: 0.5491, Val Loss: 0.4959\n",
            "Epoch [12/50], Train Loss: 0.5295, Val Loss: 0.4756\n",
            "Epoch [13/50], Train Loss: 0.5190, Val Loss: 0.4891\n",
            "Epoch [14/50], Train Loss: 0.5128, Val Loss: 0.4466\n",
            "Epoch [15/50], Train Loss: 0.5036, Val Loss: 0.4469\n",
            "Epoch [16/50], Train Loss: 0.4978, Val Loss: 0.4684\n",
            "Epoch [17/50], Train Loss: 0.4938, Val Loss: 0.4451\n",
            "Epoch [18/50], Train Loss: 0.4779, Val Loss: 0.4412\n",
            "Epoch [19/50], Train Loss: 0.4585, Val Loss: 0.4562\n",
            "Epoch [20/50], Train Loss: 0.4528, Val Loss: 0.4307\n",
            "Epoch [21/50], Train Loss: 0.4551, Val Loss: 0.4395\n",
            "Epoch [22/50], Train Loss: 0.4345, Val Loss: 0.4418\n",
            "Epoch [23/50], Train Loss: 0.4419, Val Loss: 0.4216\n",
            "Epoch [24/50], Train Loss: 0.4325, Val Loss: 0.4201\n",
            "Epoch [25/50], Train Loss: 0.4259, Val Loss: 0.3965\n",
            "Epoch [26/50], Train Loss: 0.4019, Val Loss: 0.4111\n",
            "Epoch [27/50], Train Loss: 0.4049, Val Loss: 0.4237\n",
            "Epoch [28/50], Train Loss: 0.4018, Val Loss: 0.3952\n",
            "Epoch [29/50], Train Loss: 0.3942, Val Loss: 0.3870\n",
            "Epoch [30/50], Train Loss: 0.3905, Val Loss: 0.3964\n",
            "Epoch [31/50], Train Loss: 0.3855, Val Loss: 0.3860\n",
            "Epoch [32/50], Train Loss: 0.3824, Val Loss: 0.3923\n",
            "Epoch [33/50], Train Loss: 0.3771, Val Loss: 0.3831\n",
            "Epoch [34/50], Train Loss: 0.3727, Val Loss: 0.3804\n",
            "Epoch [35/50], Train Loss: 0.3626, Val Loss: 0.3822\n",
            "Epoch [36/50], Train Loss: 0.3560, Val Loss: 0.3969\n",
            "Epoch [37/50], Train Loss: 0.3586, Val Loss: 0.3725\n",
            "Epoch [38/50], Train Loss: 0.3443, Val Loss: 0.4125\n",
            "Epoch [39/50], Train Loss: 0.3463, Val Loss: 0.3718\n",
            "Epoch [40/50], Train Loss: 0.3456, Val Loss: 0.3562\n",
            "Epoch [41/50], Train Loss: 0.3452, Val Loss: 0.3855\n",
            "Epoch [42/50], Train Loss: 0.3395, Val Loss: 0.4130\n",
            "Epoch [43/50], Train Loss: 0.3403, Val Loss: 0.3866\n",
            "Epoch [44/50], Train Loss: 0.3337, Val Loss: 0.3678\n",
            "Epoch [45/50], Train Loss: 0.3388, Val Loss: 0.3547\n",
            "Epoch [46/50], Train Loss: 0.3356, Val Loss: 0.3801\n",
            "Epoch [47/50], Train Loss: 0.3223, Val Loss: 0.3589\n",
            "Epoch [48/50], Train Loss: 0.3227, Val Loss: 0.3505\n",
            "Epoch [49/50], Train Loss: 0.3203, Val Loss: 0.3611\n",
            "Epoch [50/50], Train Loss: 0.3200, Val Loss: 0.3446\n",
            "Training completed.\n",
            "\n",
            "Starting model evaluation...\n",
            "\n",
            "Starting model evaluation...\n",
            "Testing Dataset Information:\n",
            "Number of sequences: 4\n",
            "Model Sequence length: 200\n",
            "Evaluating:   0% 0/4 [00:00<?, ?it/s]\n",
            "Sequence: data5/imu1.csv\n",
            "MAE: 0.4177\n",
            "MSE: 0.4619\n",
            "Evaluating:  25% 1/4 [00:30<01:31, 30.37s/it]\n",
            "Sequence: data5/imu2.csv\n",
            "MAE: 0.3578\n",
            "MSE: 0.3599\n",
            "Evaluating:  50% 2/4 [01:28<01:33, 46.63s/it]\n",
            "Sequence: data5/imu3.csv\n",
            "MAE: 0.3652\n",
            "MSE: 0.3413\n",
            "Evaluating:  75% 3/4 [02:23<00:50, 50.28s/it]\n",
            "Sequence: data5/imu4.csv\n",
            "MAE: 0.3526\n",
            "MSE: 0.3356\n",
            "Evaluating: 100% 4/4 [02:58<00:00, 44.65s/it]\n",
            "\n",
            "Overall Test Loss: 0.3666\n",
            "Predictions shape: (183042, 3)\n",
            "Targets shape: (183042, 3)\n",
            "\n",
            "Overall Mean Squared Error: 0.3666\n",
            "Overall Mean Absolute Error: 0.3692\n",
            "Test results logged to TensorBoard in ../../transformer_logs/20240809-051016_d_model32_nhead2_layers1_ff128_output3_batch64_dropout0.2_sequencelength200_poolinglast_returnallFalse\n",
            "Using device: cuda\n",
            "Total training samples: 3025\n",
            "Total validation samples: 462\n",
            "Total samples: 3487\n",
            "Input shape: torch.Size([200, 15])\n",
            "Target shape: torch.Size([3])\n",
            "Number of training batches: 95\n",
            "Number of validation batches: 15\n",
            "Performing mean baseline evaluation...\n",
            "Baseline Train Loss: 1.5231, Baseline Val Loss: 1.5008\n",
            "Epoch [1/25], Train Loss: 1.4562, Val Loss: 0.7572\n",
            "Epoch [2/25], Train Loss: 0.7545, Val Loss: 0.5384\n",
            "Epoch [3/25], Train Loss: 0.6300, Val Loss: 0.5349\n",
            "Epoch [4/25], Train Loss: 0.5586, Val Loss: 0.5788\n",
            "Epoch [5/25], Train Loss: 0.5258, Val Loss: 0.4646\n",
            "Epoch [6/25], Train Loss: 0.4906, Val Loss: 0.4605\n",
            "Epoch [7/25], Train Loss: 0.4657, Val Loss: 0.4157\n",
            "Epoch [8/25], Train Loss: 0.4416, Val Loss: 0.4420\n",
            "Epoch [9/25], Train Loss: 0.4268, Val Loss: 0.3979\n",
            "Epoch [10/25], Train Loss: 0.4029, Val Loss: 0.3903\n",
            "Epoch [11/25], Train Loss: 0.3754, Val Loss: 0.3554\n",
            "Epoch [12/25], Train Loss: 0.3573, Val Loss: 0.3616\n",
            "Epoch [13/25], Train Loss: 0.3393, Val Loss: 0.3276\n",
            "Epoch [14/25], Train Loss: 0.3249, Val Loss: 0.3053\n",
            "Epoch [15/25], Train Loss: 0.3044, Val Loss: 0.4043\n",
            "Epoch [16/25], Train Loss: 0.3069, Val Loss: 0.3026\n",
            "Epoch [17/25], Train Loss: 0.2855, Val Loss: 0.3400\n",
            "Epoch [18/25], Train Loss: 0.2799, Val Loss: 0.3021\n",
            "Epoch [19/25], Train Loss: 0.2688, Val Loss: 0.2886\n",
            "Epoch [20/25], Train Loss: 0.2700, Val Loss: 0.2821\n",
            "Epoch [21/25], Train Loss: 0.2490, Val Loss: 0.3461\n",
            "Epoch [22/25], Train Loss: 0.2507, Val Loss: 0.2793\n",
            "Epoch [23/25], Train Loss: 0.2512, Val Loss: 0.3174\n",
            "Epoch [24/25], Train Loss: 0.2472, Val Loss: 0.3021\n",
            "Epoch [25/25], Train Loss: 0.2319, Val Loss: 0.3405\n",
            "Training completed.\n",
            "\n",
            "Starting model evaluation...\n",
            "\n",
            "Starting model evaluation...\n",
            "Testing Dataset Information:\n",
            "Number of sequences: 4\n",
            "Model Sequence length: 200\n",
            "Evaluating:   0% 0/4 [00:00<?, ?it/s]\n",
            "Sequence: data5/imu1.csv\n",
            "MAE: 0.3962\n",
            "MSE: 0.4508\n",
            "Evaluating:  25% 1/4 [00:39<01:59, 39.67s/it]\n",
            "Sequence: data5/imu2.csv\n",
            "MAE: 0.3435\n",
            "MSE: 0.3462\n",
            "Evaluating:  50% 2/4 [01:55<02:02, 61.10s/it]\n",
            "Sequence: data5/imu3.csv\n",
            "MAE: 0.3384\n",
            "MSE: 0.3063\n",
            "Evaluating:  75% 3/4 [03:07<01:06, 66.13s/it]\n",
            "Sequence: data5/imu4.csv\n",
            "MAE: 0.3210\n",
            "MSE: 0.2854\n",
            "Evaluating: 100% 4/4 [03:54<00:00, 58.72s/it]\n",
            "\n",
            "Overall Test Loss: 0.3396\n",
            "Predictions shape: (183042, 3)\n",
            "Targets shape: (183042, 3)\n",
            "\n",
            "Overall Mean Squared Error: 0.3396\n",
            "Overall Mean Absolute Error: 0.3464\n",
            "Test results logged to TensorBoard in ../../transformer_logs/20240809-051337_d_model64_nhead4_layers2_ff256_output3_batch32_dropout0.2_sequencelength200_poolinglast_returnallFalse\n",
            "Using device: cuda\n",
            "Total training samples: 3025\n",
            "Total validation samples: 462\n",
            "Total samples: 3487\n",
            "Input shape: torch.Size([200, 15])\n",
            "Target shape: torch.Size([3])\n",
            "Number of training batches: 95\n",
            "Number of validation batches: 15\n",
            "Performing mean baseline evaluation...\n",
            "Baseline Train Loss: 1.5231, Baseline Val Loss: 1.5008\n",
            "Epoch [1/25], Train Loss: 1.4747, Val Loss: 0.9966\n",
            "Epoch [2/25], Train Loss: 0.8805, Val Loss: 0.7107\n",
            "Epoch [3/25], Train Loss: 0.6599, Val Loss: 0.7333\n",
            "Epoch [4/25], Train Loss: 0.6199, Val Loss: 0.5962\n",
            "Epoch [5/25], Train Loss: 0.5595, Val Loss: 0.5994\n",
            "Epoch [6/25], Train Loss: 0.5430, Val Loss: 0.5976\n",
            "Epoch [7/25], Train Loss: 0.5045, Val Loss: 0.5609\n",
            "Epoch [8/25], Train Loss: 0.4798, Val Loss: 0.5309\n",
            "Epoch [9/25], Train Loss: 0.4576, Val Loss: 0.5186\n",
            "Epoch [10/25], Train Loss: 0.4335, Val Loss: 0.4638\n",
            "Epoch [11/25], Train Loss: 0.4307, Val Loss: 0.4244\n",
            "Epoch [12/25], Train Loss: 0.4132, Val Loss: 0.5188\n",
            "Epoch [13/25], Train Loss: 0.3887, Val Loss: 0.5161\n",
            "Epoch [14/25], Train Loss: 0.3831, Val Loss: 0.4248\n",
            "Epoch [15/25], Train Loss: 0.3779, Val Loss: 0.4328\n",
            "Epoch [16/25], Train Loss: 0.3713, Val Loss: 0.3991\n",
            "Epoch [17/25], Train Loss: 0.3656, Val Loss: 0.4104\n",
            "Epoch [18/25], Train Loss: 0.3605, Val Loss: 0.3741\n",
            "Epoch [19/25], Train Loss: 0.3239, Val Loss: 0.4163\n",
            "Epoch [20/25], Train Loss: 0.3210, Val Loss: 0.3809\n",
            "Epoch [21/25], Train Loss: 0.2904, Val Loss: 0.3503\n",
            "Epoch [22/25], Train Loss: 0.2910, Val Loss: 0.3819\n",
            "Epoch [23/25], Train Loss: 0.2837, Val Loss: 0.4510\n",
            "Epoch [24/25], Train Loss: 0.2867, Val Loss: 0.3754\n",
            "Epoch [25/25], Train Loss: 0.2728, Val Loss: 0.3413\n",
            "Training completed.\n",
            "\n",
            "Starting model evaluation...\n",
            "\n",
            "Starting model evaluation...\n",
            "Testing Dataset Information:\n",
            "Number of sequences: 4\n",
            "Model Sequence length: 200\n",
            "Evaluating:   0% 0/4 [00:00<?, ?it/s]\n",
            "Sequence: data5/imu1.csv\n",
            "MAE: 0.4095\n",
            "MSE: 0.4846\n",
            "Evaluating:  25% 1/4 [01:16<03:49, 76.46s/it]\n",
            "Sequence: data5/imu2.csv\n",
            "MAE: 0.3487\n",
            "MSE: 0.3822\n",
            "Evaluating:  50% 2/4 [03:43<03:55, 117.94s/it]\n",
            "Sequence: data5/imu3.csv\n",
            "MAE: 0.3516\n",
            "MSE: 0.3699\n",
            "Evaluating:  75% 3/4 [06:02<02:07, 127.40s/it]\n",
            "Sequence: data5/imu4.csv\n",
            "MAE: 0.3275\n",
            "MSE: 0.3268\n",
            "Evaluating: 100% 4/4 [07:32<00:00, 113.19s/it]\n",
            "\n",
            "Overall Test Loss: 0.3847\n",
            "Predictions shape: (183042, 3)\n",
            "Targets shape: (183042, 3)\n",
            "\n",
            "Overall Mean Squared Error: 0.3847\n",
            "Overall Mean Absolute Error: 0.3556\n",
            "Test results logged to TensorBoard in ../../transformer_logs/20240809-051800_d_model64_nhead4_layers6_ff256_output3_batch32_dropout0.2_sequencelength200_poolinglast_returnallFalse\n",
            "Using device: cuda\n",
            "Total training samples: 3025\n",
            "Total validation samples: 462\n",
            "Total samples: 3487\n",
            "Input shape: torch.Size([200, 15])\n",
            "Target shape: torch.Size([3])\n",
            "Number of training batches: 190\n",
            "Number of validation batches: 29\n",
            "Performing mean baseline evaluation...\n",
            "Baseline Train Loss: 1.5231, Baseline Val Loss: 1.5008\n",
            "Epoch [1/50], Train Loss: 1.2826, Val Loss: 0.6879\n",
            "Epoch [2/50], Train Loss: 0.6807, Val Loss: 0.5884\n",
            "Epoch [3/50], Train Loss: 0.5718, Val Loss: 0.5509\n",
            "Epoch [4/50], Train Loss: 0.5381, Val Loss: 0.5874\n",
            "Epoch [5/50], Train Loss: 0.4931, Val Loss: 0.4617\n",
            "Epoch [6/50], Train Loss: 0.4725, Val Loss: 0.4438\n",
            "Epoch [7/50], Train Loss: 0.4306, Val Loss: 0.4143\n",
            "Epoch [8/50], Train Loss: 0.4080, Val Loss: 0.3501\n",
            "Epoch [9/50], Train Loss: 0.3735, Val Loss: 0.3959\n",
            "Epoch [10/50], Train Loss: 0.3425, Val Loss: 0.3671\n",
            "Epoch [11/50], Train Loss: 0.3229, Val Loss: 0.3652\n",
            "Epoch [12/50], Train Loss: 0.3068, Val Loss: 0.2853\n",
            "Epoch [13/50], Train Loss: 0.2927, Val Loss: 0.3302\n",
            "Epoch [14/50], Train Loss: 0.2882, Val Loss: 0.4438\n",
            "Epoch [15/50], Train Loss: 0.2615, Val Loss: 0.3146\n",
            "Epoch [16/50], Train Loss: 0.2637, Val Loss: 0.3818\n",
            "Epoch [17/50], Train Loss: 0.2573, Val Loss: 0.3510\n",
            "Epoch [18/50], Train Loss: 0.2493, Val Loss: 0.4028\n",
            "Epoch [19/50], Train Loss: 0.2373, Val Loss: 0.3564\n",
            "Epoch [20/50], Train Loss: 0.2259, Val Loss: 0.3243\n",
            "Epoch [21/50], Train Loss: 0.2339, Val Loss: 0.3060\n",
            "Epoch [22/50], Train Loss: 0.2256, Val Loss: 0.2676\n",
            "Epoch [23/50], Train Loss: 0.2153, Val Loss: 0.3273\n",
            "Epoch [24/50], Train Loss: 0.2054, Val Loss: 0.3575\n",
            "Epoch [25/50], Train Loss: 0.2024, Val Loss: 0.3224\n",
            "Epoch [26/50], Train Loss: 0.2044, Val Loss: 0.3840\n",
            "Epoch [27/50], Train Loss: 0.1957, Val Loss: 0.4353\n",
            "Epoch [28/50], Train Loss: 0.1947, Val Loss: 0.3838\n",
            "Epoch [29/50], Train Loss: 0.1912, Val Loss: 0.3968\n",
            "Epoch [30/50], Train Loss: 0.1848, Val Loss: 0.4231\n",
            "Epoch [31/50], Train Loss: 0.1859, Val Loss: 0.3546\n",
            "Epoch [32/50], Train Loss: 0.1756, Val Loss: 0.3602\n",
            "Epoch [33/50], Train Loss: 0.1843, Val Loss: 0.3260\n",
            "Epoch [34/50], Train Loss: 0.1720, Val Loss: 0.3302\n",
            "Epoch [35/50], Train Loss: 0.1625, Val Loss: 0.3300\n",
            "Epoch [36/50], Train Loss: 0.1665, Val Loss: 0.3393\n",
            "Epoch [37/50], Train Loss: 0.1496, Val Loss: 0.3489\n",
            "Epoch [38/50], Train Loss: 0.1574, Val Loss: 0.3289\n",
            "Epoch [39/50], Train Loss: 0.1618, Val Loss: 0.3191\n",
            "Epoch [40/50], Train Loss: 0.1592, Val Loss: 0.3905\n",
            "Epoch [41/50], Train Loss: 0.1519, Val Loss: 0.3610\n",
            "Epoch [42/50], Train Loss: 0.1461, Val Loss: 0.3892\n",
            "Epoch [43/50], Train Loss: 0.1355, Val Loss: 0.4061\n",
            "Epoch [44/50], Train Loss: 0.1454, Val Loss: 0.4120\n",
            "Epoch [45/50], Train Loss: 0.1444, Val Loss: 0.4312\n",
            "Epoch [46/50], Train Loss: 0.1349, Val Loss: 0.4158\n",
            "Epoch [47/50], Train Loss: 0.1428, Val Loss: 0.3791\n",
            "Epoch [48/50], Train Loss: 0.1326, Val Loss: 0.3901\n",
            "Epoch [49/50], Train Loss: 0.1358, Val Loss: 0.3756\n",
            "Epoch [50/50], Train Loss: 0.1279, Val Loss: 0.3110\n",
            "Training completed.\n",
            "\n",
            "Starting model evaluation...\n",
            "\n",
            "Starting model evaluation...\n",
            "Testing Dataset Information:\n",
            "Number of sequences: 4\n",
            "Model Sequence length: 200\n",
            "Evaluating:   0% 0/4 [00:00<?, ?it/s]\n",
            "Sequence: data5/imu1.csv\n",
            "MAE: 0.3788\n",
            "MSE: 0.4344\n",
            "Evaluating:  25% 1/4 [00:39<01:59, 39.92s/it]\n",
            "Sequence: data5/imu2.csv\n",
            "MAE: 0.3347\n",
            "MSE: 0.3629\n",
            "Evaluating:  50% 2/4 [01:56<02:03, 61.77s/it]\n",
            "Sequence: data5/imu3.csv\n",
            "MAE: 0.3386\n",
            "MSE: 0.3462\n",
            "Evaluating:  75% 3/4 [03:09<01:06, 66.45s/it]\n",
            "Sequence: data5/imu4.csv\n",
            "MAE: 0.3130\n",
            "MSE: 0.3127\n",
            "Evaluating: 100% 4/4 [03:55<00:00, 58.96s/it]\n",
            "\n",
            "Overall Test Loss: 0.3599\n",
            "Predictions shape: (183042, 3)\n",
            "Targets shape: (183042, 3)\n",
            "\n",
            "Overall Mean Squared Error: 0.3599\n",
            "Overall Mean Absolute Error: 0.3391\n",
            "Test results logged to TensorBoard in ../../transformer_logs/20240809-052622_d_model128_nhead8_layers2_ff1024_output3_batch16_dropout0.2_sequencelength200_poolinglast_returnallFalse\n",
            "Using device: cuda\n",
            "Total training samples: 3025\n",
            "Total validation samples: 462\n",
            "Total samples: 3487\n",
            "Input shape: torch.Size([200, 15])\n",
            "Target shape: torch.Size([3])\n",
            "Number of training batches: 190\n",
            "Number of validation batches: 29\n",
            "Performing mean baseline evaluation...\n",
            "Baseline Train Loss: 1.5231, Baseline Val Loss: 1.5008\n",
            "Epoch [1/50], Train Loss: 1.5227, Val Loss: 0.8696\n",
            "Epoch [2/50], Train Loss: 0.6985, Val Loss: 0.7552\n",
            "Epoch [3/50], Train Loss: 0.6131, Val Loss: 0.6512\n",
            "Epoch [4/50], Train Loss: 0.5381, Val Loss: 0.5835\n",
            "Epoch [5/50], Train Loss: 0.5106, Val Loss: 0.5083\n",
            "Epoch [6/50], Train Loss: 0.4854, Val Loss: 0.5288\n",
            "Epoch [7/50], Train Loss: 0.4548, Val Loss: 0.5359\n",
            "Epoch [8/50], Train Loss: 0.4349, Val Loss: 0.3905\n",
            "Epoch [9/50], Train Loss: 0.4004, Val Loss: 0.3711\n",
            "Epoch [10/50], Train Loss: 0.3790, Val Loss: 0.4027\n",
            "Epoch [11/50], Train Loss: 0.3702, Val Loss: 0.4443\n",
            "Epoch [12/50], Train Loss: 0.3544, Val Loss: 0.4461\n",
            "Epoch [13/50], Train Loss: 0.3427, Val Loss: 0.3651\n",
            "Epoch [14/50], Train Loss: 0.3279, Val Loss: 0.3857\n",
            "Epoch [15/50], Train Loss: 0.3169, Val Loss: 0.3192\n",
            "Epoch [16/50], Train Loss: 0.2925, Val Loss: 0.3222\n",
            "Epoch [17/50], Train Loss: 0.3018, Val Loss: 0.4395\n",
            "Epoch [18/50], Train Loss: 0.2810, Val Loss: 0.3594\n",
            "Epoch [19/50], Train Loss: 0.2709, Val Loss: 0.3289\n",
            "Epoch [20/50], Train Loss: 0.2534, Val Loss: 0.3547\n",
            "Epoch [21/50], Train Loss: 0.2592, Val Loss: 0.3362\n",
            "Epoch [22/50], Train Loss: 0.2488, Val Loss: 0.4017\n",
            "Epoch [23/50], Train Loss: 0.2541, Val Loss: 0.4065\n",
            "Epoch [24/50], Train Loss: 0.2340, Val Loss: 0.4229\n",
            "Epoch [25/50], Train Loss: 0.2316, Val Loss: 0.3922\n",
            "Epoch [26/50], Train Loss: 0.2282, Val Loss: 0.3571\n",
            "Epoch [27/50], Train Loss: 0.2386, Val Loss: 0.4429\n",
            "Epoch [28/50], Train Loss: 0.2265, Val Loss: 0.4147\n",
            "Epoch [29/50], Train Loss: 0.2196, Val Loss: 0.3672\n",
            "Epoch [30/50], Train Loss: 0.2165, Val Loss: 0.4350\n",
            "Epoch [31/50], Train Loss: 0.2099, Val Loss: 0.4625\n",
            "Epoch [32/50], Train Loss: 0.1954, Val Loss: 0.3947\n",
            "Epoch [33/50], Train Loss: 0.1977, Val Loss: 0.4129\n",
            "Epoch [34/50], Train Loss: 0.1940, Val Loss: 0.3687\n",
            "Epoch [35/50], Train Loss: 0.1942, Val Loss: 0.3999\n",
            "Epoch [36/50], Train Loss: 0.1980, Val Loss: 0.4030\n",
            "Epoch [37/50], Train Loss: 0.1907, Val Loss: 0.4538\n",
            "Epoch [38/50], Train Loss: 0.1852, Val Loss: 0.4062\n",
            "Epoch [39/50], Train Loss: 0.1881, Val Loss: 0.3689\n",
            "Epoch [40/50], Train Loss: 0.1754, Val Loss: 0.4976\n",
            "Epoch [41/50], Train Loss: 0.1881, Val Loss: 0.4243\n",
            "Epoch [42/50], Train Loss: 0.1784, Val Loss: 0.4331\n",
            "Epoch [43/50], Train Loss: 0.1774, Val Loss: 0.4438\n",
            "Epoch [44/50], Train Loss: 0.1686, Val Loss: 0.3954\n",
            "Epoch [45/50], Train Loss: 0.1723, Val Loss: 0.4023\n",
            "Epoch [46/50], Train Loss: 0.1729, Val Loss: 0.4617\n",
            "Epoch [47/50], Train Loss: 0.1612, Val Loss: 0.4610\n",
            "Epoch [48/50], Train Loss: 0.1681, Val Loss: 0.4186\n",
            "Epoch [49/50], Train Loss: 0.1571, Val Loss: 0.4302\n",
            "Epoch [50/50], Train Loss: 0.1593, Val Loss: 0.3705\n",
            "Training completed.\n",
            "\n",
            "Starting model evaluation...\n",
            "\n",
            "Starting model evaluation...\n",
            "Testing Dataset Information:\n",
            "Number of sequences: 4\n",
            "Model Sequence length: 200\n",
            "Evaluating:   0% 0/4 [00:00<?, ?it/s]\n",
            "Sequence: data5/imu1.csv\n",
            "MAE: 0.3960\n",
            "MSE: 0.4362\n",
            "Evaluating:  25% 1/4 [00:39<01:59, 39.81s/it]\n",
            "Sequence: data5/imu2.csv\n",
            "MAE: 0.3629\n",
            "MSE: 0.3700\n",
            "Evaluating:  50% 2/4 [01:56<02:02, 61.27s/it]\n",
            "Sequence: data5/imu3.csv\n",
            "MAE: 0.3513\n",
            "MSE: 0.3144\n",
            "Evaluating:  75% 3/4 [03:08<01:06, 66.20s/it]\n",
            "Sequence: data5/imu4.csv\n",
            "MAE: 0.3483\n",
            "MSE: 0.3126\n",
            "Evaluating: 100% 4/4 [03:55<00:00, 58.78s/it]\n",
            "\n",
            "Overall Test Loss: 0.3527\n",
            "Predictions shape: (183042, 3)\n",
            "Targets shape: (183042, 3)\n",
            "\n",
            "Overall Mean Squared Error: 0.3527\n",
            "Overall Mean Absolute Error: 0.3621\n",
            "Test results logged to TensorBoard in ../../transformer_logs/20240809-053134_d_model128_nhead8_layers2_ff1024_output3_batch16_dropout0.3_sequencelength200_poolinglast_returnallFalse\n",
            "Using device: cuda\n",
            "Total training samples: 3025\n",
            "Total validation samples: 462\n",
            "Total samples: 3487\n",
            "Input shape: torch.Size([200, 15])\n",
            "Target shape: torch.Size([3])\n",
            "Number of training batches: 95\n",
            "Number of validation batches: 15\n",
            "Performing mean baseline evaluation...\n",
            "Baseline Train Loss: 1.5231, Baseline Val Loss: 1.5008\n",
            "Epoch [1/50], Train Loss: 1.3436, Val Loss: 1.1812\n",
            "Epoch [2/50], Train Loss: 0.7333, Val Loss: 0.6963\n",
            "Epoch [3/50], Train Loss: 0.5653, Val Loss: 0.7030\n",
            "Epoch [4/50], Train Loss: 0.5114, Val Loss: 0.5879\n",
            "Epoch [5/50], Train Loss: 0.4594, Val Loss: 0.5231\n",
            "Epoch [6/50], Train Loss: 0.4333, Val Loss: 0.5530\n",
            "Epoch [7/50], Train Loss: 0.4173, Val Loss: 0.4792\n",
            "Epoch [8/50], Train Loss: 0.4003, Val Loss: 0.4948\n",
            "Epoch [9/50], Train Loss: 0.3725, Val Loss: 0.4440\n",
            "Epoch [10/50], Train Loss: 0.3628, Val Loss: 0.4269\n",
            "Epoch [11/50], Train Loss: 0.3376, Val Loss: 0.4562\n",
            "Epoch [12/50], Train Loss: 0.3294, Val Loss: 0.4564\n",
            "Epoch [13/50], Train Loss: 0.3132, Val Loss: 0.4672\n",
            "Epoch [14/50], Train Loss: 0.2971, Val Loss: 0.4053\n",
            "Epoch [15/50], Train Loss: 0.2983, Val Loss: 0.4175\n",
            "Epoch [16/50], Train Loss: 0.2729, Val Loss: 0.4676\n",
            "Epoch [17/50], Train Loss: 0.2782, Val Loss: 0.3549\n",
            "Epoch [18/50], Train Loss: 0.2554, Val Loss: 0.4567\n",
            "Epoch [19/50], Train Loss: 0.2517, Val Loss: 0.4022\n",
            "Epoch [20/50], Train Loss: 0.2451, Val Loss: 0.4131\n",
            "Epoch [21/50], Train Loss: 0.2469, Val Loss: 0.4122\n",
            "Epoch [22/50], Train Loss: 0.2259, Val Loss: 0.4333\n",
            "Epoch [23/50], Train Loss: 0.2248, Val Loss: 0.5157\n",
            "Epoch [24/50], Train Loss: 0.2304, Val Loss: 0.3975\n",
            "Epoch [25/50], Train Loss: 0.2221, Val Loss: 0.3839\n",
            "Epoch [26/50], Train Loss: 0.2173, Val Loss: 0.4290\n",
            "Epoch [27/50], Train Loss: 0.2114, Val Loss: 0.4198\n",
            "Epoch [28/50], Train Loss: 0.2064, Val Loss: 0.4663\n",
            "Epoch [29/50], Train Loss: 0.2054, Val Loss: 0.4562\n",
            "Epoch [30/50], Train Loss: 0.2020, Val Loss: 0.4814\n",
            "Epoch [31/50], Train Loss: 0.1946, Val Loss: 0.4339\n",
            "Epoch [32/50], Train Loss: 0.1840, Val Loss: 0.4886\n",
            "Epoch [33/50], Train Loss: 0.1913, Val Loss: 0.5047\n",
            "Epoch [34/50], Train Loss: 0.1752, Val Loss: 0.4340\n",
            "Epoch [35/50], Train Loss: 0.1736, Val Loss: 0.5223\n",
            "Epoch [36/50], Train Loss: 0.1799, Val Loss: 0.4410\n",
            "Epoch [37/50], Train Loss: 0.1833, Val Loss: 0.4286\n",
            "Epoch [38/50], Train Loss: 0.1769, Val Loss: 0.4690\n",
            "Epoch [39/50], Train Loss: 0.1705, Val Loss: 0.4247\n",
            "Epoch [40/50], Train Loss: 0.1615, Val Loss: 0.4385\n",
            "Epoch [41/50], Train Loss: 0.1604, Val Loss: 0.4139\n",
            "Epoch [42/50], Train Loss: 0.1543, Val Loss: 0.4807\n",
            "Epoch [43/50], Train Loss: 0.1624, Val Loss: 0.4345\n",
            "Epoch [44/50], Train Loss: 0.1495, Val Loss: 0.4520\n",
            "Epoch [45/50], Train Loss: 0.1466, Val Loss: 0.3992\n",
            "Epoch [46/50], Train Loss: 0.1435, Val Loss: 0.4513\n",
            "Epoch [47/50], Train Loss: 0.1426, Val Loss: 0.4948\n",
            "Epoch [48/50], Train Loss: 0.1409, Val Loss: 0.5276\n",
            "Epoch [49/50], Train Loss: 0.1457, Val Loss: 0.4282\n",
            "Epoch [50/50], Train Loss: 0.1410, Val Loss: 0.4465\n",
            "Training completed.\n",
            "\n",
            "Starting model evaluation...\n",
            "\n",
            "Starting model evaluation...\n",
            "Testing Dataset Information:\n",
            "Number of sequences: 4\n",
            "Model Sequence length: 200\n",
            "Evaluating:   0% 0/4 [00:00<?, ?it/s]\n",
            "Sequence: data5/imu1.csv\n",
            "MAE: 0.4550\n",
            "MSE: 0.5337\n",
            "Evaluating:  25% 1/4 [00:39<01:59, 39.87s/it]\n",
            "Sequence: data5/imu2.csv\n",
            "MAE: 0.4005\n",
            "MSE: 0.4230\n",
            "Evaluating:  50% 2/4 [01:55<02:02, 61.19s/it]\n",
            "Sequence: data5/imu3.csv\n",
            "MAE: 0.4111\n",
            "MSE: 0.4193\n",
            "Evaluating:  75% 3/4 [03:07<01:06, 66.10s/it]\n",
            "Sequence: data5/imu4.csv\n",
            "MAE: 0.3766\n",
            "MSE: 0.3626\n",
            "Evaluating: 100% 4/4 [03:54<00:00, 58.71s/it]\n",
            "\n",
            "Overall Test Loss: 0.4286\n",
            "Predictions shape: (183042, 3)\n",
            "Targets shape: (183042, 3)\n",
            "\n",
            "Overall Mean Squared Error: 0.4286\n",
            "Overall Mean Absolute Error: 0.4082\n",
            "Test results logged to TensorBoard in ../../transformer_logs/20240809-053646_d_model64_nhead4_layers2_ff256_output3_batch32_dropout0.2_sequencelength200_poolingmean_returnallFalse\n",
            "Using device: cuda\n",
            "Total training samples: 3025\n",
            "Total validation samples: 462\n",
            "Total samples: 3487\n",
            "Input shape: torch.Size([200, 15])\n",
            "Target shape: torch.Size([3])\n",
            "Number of training batches: 95\n",
            "Number of validation batches: 15\n",
            "Performing mean baseline evaluation...\n",
            "Baseline Train Loss: 1.5231, Baseline Val Loss: 1.5008\n",
            "Epoch [1/50], Train Loss: 1.4474, Val Loss: 0.9289\n",
            "Epoch [2/50], Train Loss: 0.7421, Val Loss: 0.6753\n",
            "Epoch [3/50], Train Loss: 0.6236, Val Loss: 0.5451\n",
            "Epoch [4/50], Train Loss: 0.5473, Val Loss: 0.5651\n",
            "Epoch [5/50], Train Loss: 0.5031, Val Loss: 0.5282\n",
            "Epoch [6/50], Train Loss: 0.4703, Val Loss: 0.4723\n",
            "Epoch [7/50], Train Loss: 0.4556, Val Loss: 0.4937\n",
            "Epoch [8/50], Train Loss: 0.4372, Val Loss: 0.4457\n",
            "Epoch [9/50], Train Loss: 0.4045, Val Loss: 0.4301\n",
            "Epoch [10/50], Train Loss: 0.3875, Val Loss: 0.3773\n",
            "Epoch [11/50], Train Loss: 0.3613, Val Loss: 0.3603\n",
            "Epoch [12/50], Train Loss: 0.3436, Val Loss: 0.4344\n",
            "Epoch [13/50], Train Loss: 0.3374, Val Loss: 0.4277\n",
            "Epoch [14/50], Train Loss: 0.3250, Val Loss: 0.4040\n",
            "Epoch [15/50], Train Loss: 0.3084, Val Loss: 0.3894\n",
            "Epoch [16/50], Train Loss: 0.3014, Val Loss: 0.3634\n",
            "Epoch [17/50], Train Loss: 0.2915, Val Loss: 0.3788\n",
            "Epoch [18/50], Train Loss: 0.2670, Val Loss: 0.3732\n",
            "Epoch [19/50], Train Loss: 0.2651, Val Loss: 0.3592\n",
            "Epoch [20/50], Train Loss: 0.2557, Val Loss: 0.3540\n",
            "Epoch [21/50], Train Loss: 0.2439, Val Loss: 0.3701\n",
            "Epoch [22/50], Train Loss: 0.2371, Val Loss: 0.3158\n",
            "Epoch [23/50], Train Loss: 0.2403, Val Loss: 0.3500\n",
            "Epoch [24/50], Train Loss: 0.2289, Val Loss: 0.4153\n",
            "Epoch [25/50], Train Loss: 0.2245, Val Loss: 0.3101\n",
            "Epoch [26/50], Train Loss: 0.2214, Val Loss: 0.3901\n",
            "Epoch [27/50], Train Loss: 0.2152, Val Loss: 0.4707\n",
            "Epoch [28/50], Train Loss: 0.2214, Val Loss: 0.3688\n",
            "Epoch [29/50], Train Loss: 0.1989, Val Loss: 0.3401\n",
            "Epoch [30/50], Train Loss: 0.2021, Val Loss: 0.3479\n",
            "Epoch [31/50], Train Loss: 0.1899, Val Loss: 0.3493\n",
            "Epoch [32/50], Train Loss: 0.1906, Val Loss: 0.3686\n",
            "Epoch [33/50], Train Loss: 0.1936, Val Loss: 0.3195\n",
            "Epoch [34/50], Train Loss: 0.1863, Val Loss: 0.3401\n",
            "Epoch [35/50], Train Loss: 0.1747, Val Loss: 0.3442\n",
            "Epoch [36/50], Train Loss: 0.1789, Val Loss: 0.3681\n",
            "Epoch [37/50], Train Loss: 0.1811, Val Loss: 0.3985\n",
            "Epoch [38/50], Train Loss: 0.1671, Val Loss: 0.4144\n",
            "Epoch [39/50], Train Loss: 0.1718, Val Loss: 0.3400\n",
            "Epoch [40/50], Train Loss: 0.1693, Val Loss: 0.3754\n",
            "Epoch [41/50], Train Loss: 0.1604, Val Loss: 0.3882\n",
            "Epoch [42/50], Train Loss: 0.1526, Val Loss: 0.3875\n",
            "Epoch [43/50], Train Loss: 0.1617, Val Loss: 0.3605\n",
            "Epoch [44/50], Train Loss: 0.1545, Val Loss: 0.3624\n",
            "Epoch [45/50], Train Loss: 0.1464, Val Loss: 0.3948\n",
            "Epoch [46/50], Train Loss: 0.1449, Val Loss: 0.4055\n",
            "Epoch [47/50], Train Loss: 0.1427, Val Loss: 0.3525\n",
            "Epoch [48/50], Train Loss: 0.1497, Val Loss: 0.3949\n",
            "Epoch [49/50], Train Loss: 0.1407, Val Loss: 0.3407\n",
            "Epoch [50/50], Train Loss: 0.1417, Val Loss: 0.4581\n",
            "Training completed.\n",
            "\n",
            "Starting model evaluation...\n",
            "\n",
            "Starting model evaluation...\n",
            "Testing Dataset Information:\n",
            "Number of sequences: 4\n",
            "Model Sequence length: 200\n",
            "Evaluating:   0% 0/4 [00:00<?, ?it/s]\n",
            "Sequence: data5/imu1.csv\n",
            "MAE: 0.3859\n",
            "MSE: 0.4131\n",
            "Evaluating:  25% 1/4 [00:39<01:59, 39.71s/it]\n",
            "Sequence: data5/imu2.csv\n",
            "MAE: 0.3422\n",
            "MSE: 0.3270\n",
            "Evaluating:  50% 2/4 [01:55<02:02, 61.21s/it]\n",
            "Sequence: data5/imu3.csv\n",
            "MAE: 0.3425\n",
            "MSE: 0.3165\n",
            "Evaluating:  75% 3/4 [03:07<01:06, 66.07s/it]\n",
            "Sequence: data5/imu4.csv\n",
            "MAE: 0.3297\n",
            "MSE: 0.3094\n",
            "Evaluating: 100% 4/4 [03:54<00:00, 58.70s/it]\n",
            "\n",
            "Overall Test Loss: 0.3349\n",
            "Predictions shape: (183042, 3)\n",
            "Targets shape: (183042, 3)\n",
            "\n",
            "Overall Mean Squared Error: 0.3349\n",
            "Overall Mean Absolute Error: 0.3472\n",
            "Test results logged to TensorBoard in ../../transformer_logs/20240809-054126_d_model64_nhead4_layers2_ff256_output3_batch32_dropout0.2_sequencelength200_poolinglast_returnallTrue\n",
            "Using device: cuda\n",
            "Total training samples: 3025\n",
            "Total validation samples: 462\n",
            "Total samples: 3487\n",
            "Input shape: torch.Size([200, 15])\n",
            "Target shape: torch.Size([3])\n",
            "Number of training batches: 24\n",
            "Number of validation batches: 4\n",
            "Performing mean baseline evaluation...\n",
            "Baseline Train Loss: 1.5231, Baseline Val Loss: 1.5008\n",
            "Epoch [1/30], Train Loss: 1.8742, Val Loss: 0.8744\n",
            "Epoch [2/30], Train Loss: 1.1122, Val Loss: 0.7432\n",
            "Epoch [3/30], Train Loss: 0.9048, Val Loss: 0.6858\n",
            "Epoch [4/30], Train Loss: 0.7734, Val Loss: 0.6137\n",
            "Epoch [5/30], Train Loss: 0.6820, Val Loss: 0.5613\n",
            "Epoch [6/30], Train Loss: 0.6049, Val Loss: 0.5289\n",
            "Epoch [7/30], Train Loss: 0.5645, Val Loss: 0.5352\n",
            "Epoch [8/30], Train Loss: 0.5594, Val Loss: 0.5040\n",
            "Epoch [9/30], Train Loss: 0.5331, Val Loss: 0.5264\n",
            "Epoch [10/30], Train Loss: 0.5137, Val Loss: 0.4772\n",
            "Epoch [11/30], Train Loss: 0.4932, Val Loss: 0.4570\n",
            "Epoch [12/30], Train Loss: 0.4780, Val Loss: 0.4867\n",
            "Epoch [13/30], Train Loss: 0.4659, Val Loss: 0.4366\n",
            "Epoch [14/30], Train Loss: 0.4697, Val Loss: 0.4745\n",
            "Epoch [15/30], Train Loss: 0.4418, Val Loss: 0.4791\n",
            "Epoch [16/30], Train Loss: 0.4328, Val Loss: 0.4480\n",
            "Epoch [17/30], Train Loss: 0.4121, Val Loss: 0.3924\n",
            "Epoch [18/30], Train Loss: 0.4190, Val Loss: 0.3899\n",
            "Epoch [19/30], Train Loss: 0.4000, Val Loss: 0.3897\n",
            "Epoch [20/30], Train Loss: 0.3927, Val Loss: 0.3749\n",
            "Epoch [21/30], Train Loss: 0.3838, Val Loss: 0.4009\n",
            "Epoch [22/30], Train Loss: 0.3738, Val Loss: 0.3950\n",
            "Epoch [23/30], Train Loss: 0.3686, Val Loss: 0.3544\n",
            "Epoch [24/30], Train Loss: 0.3707, Val Loss: 0.3743\n",
            "Epoch [25/30], Train Loss: 0.3537, Val Loss: 0.3542\n",
            "Epoch [26/30], Train Loss: 0.3480, Val Loss: 0.3970\n",
            "Epoch [27/30], Train Loss: 0.3308, Val Loss: 0.3551\n",
            "Epoch [28/30], Train Loss: 0.3140, Val Loss: 0.3734\n",
            "Epoch [29/30], Train Loss: 0.3147, Val Loss: 0.4128\n",
            "Epoch [30/30], Train Loss: 0.3214, Val Loss: 0.3583\n",
            "Training completed.\n",
            "\n",
            "Starting model evaluation...\n",
            "\n",
            "Starting model evaluation...\n",
            "Testing Dataset Information:\n",
            "Number of sequences: 4\n",
            "Model Sequence length: 200\n",
            "Evaluating:   0% 0/4 [00:00<?, ?it/s]\n",
            "Sequence: data5/imu1.csv\n",
            "MAE: 0.4335\n",
            "MSE: 0.4732\n",
            "Evaluating:  25% 1/4 [00:40<02:00, 40.18s/it]\n",
            "Sequence: data5/imu2.csv\n",
            "MAE: 0.3862\n",
            "MSE: 0.3868\n",
            "Evaluating:  50% 2/4 [01:57<02:03, 61.73s/it]\n",
            "Sequence: data5/imu3.csv\n",
            "MAE: 0.3902\n",
            "MSE: 0.3678\n",
            "Evaluating:  75% 3/4 [03:10<01:06, 66.95s/it]\n",
            "Sequence: data5/imu4.csv\n",
            "MAE: 0.3766\n",
            "MSE: 0.3504\n",
            "Evaluating: 100% 4/4 [03:57<00:00, 59.41s/it]\n",
            "\n",
            "Overall Test Loss: 0.3883\n",
            "Predictions shape: (183042, 3)\n",
            "Targets shape: (183042, 3)\n",
            "\n",
            "Overall Mean Squared Error: 0.3883\n",
            "Overall Mean Absolute Error: 0.3935\n",
            "Test results logged to TensorBoard in ../../transformer_logs/20240809-054604_d_model64_nhead4_layers2_ff256_output3_batch128_dropout0.2_sequencelength200_poolinglast_returnallFalse\n",
            "Using device: cuda\n",
            "Total training samples: 3025\n",
            "Total validation samples: 462\n",
            "Total samples: 3487\n",
            "Input shape: torch.Size([200, 15])\n",
            "Target shape: torch.Size([3])\n",
            "Number of training batches: 95\n",
            "Number of validation batches: 15\n",
            "Performing mean baseline evaluation...\n",
            "Baseline Train Loss: 1.5231, Baseline Val Loss: 1.5008\n",
            "Epoch [1/75], Train Loss: 2.5213, Val Loss: 1.0543\n",
            "Epoch [2/75], Train Loss: 1.1799, Val Loss: 0.8438\n",
            "Epoch [3/75], Train Loss: 0.8655, Val Loss: 0.7698\n",
            "Epoch [4/75], Train Loss: 0.7506, Val Loss: 0.7165\n",
            "Epoch [5/75], Train Loss: 0.7039, Val Loss: 0.6122\n",
            "Epoch [6/75], Train Loss: 0.6579, Val Loss: 0.6970\n",
            "Epoch [7/75], Train Loss: 0.6328, Val Loss: 0.7331\n",
            "Epoch [8/75], Train Loss: 0.5976, Val Loss: 0.7366\n",
            "Epoch [9/75], Train Loss: 0.5976, Val Loss: 0.6285\n",
            "Epoch [10/75], Train Loss: 0.5459, Val Loss: 0.6089\n",
            "Epoch [11/75], Train Loss: 0.5347, Val Loss: 0.5800\n",
            "Epoch [12/75], Train Loss: 0.5160, Val Loss: 0.5377\n",
            "Epoch [13/75], Train Loss: 0.4810, Val Loss: 0.5095\n",
            "Epoch [14/75], Train Loss: 0.4917, Val Loss: 0.4961\n",
            "Epoch [15/75], Train Loss: 0.4605, Val Loss: 0.5006\n",
            "Epoch [16/75], Train Loss: 0.4639, Val Loss: 0.5085\n",
            "Epoch [17/75], Train Loss: 0.4578, Val Loss: 0.4638\n",
            "Epoch [18/75], Train Loss: 0.4231, Val Loss: 0.4846\n",
            "Epoch [19/75], Train Loss: 0.4226, Val Loss: 0.5923\n",
            "Epoch [20/75], Train Loss: 0.4253, Val Loss: 0.4528\n",
            "Epoch [21/75], Train Loss: 0.4141, Val Loss: 0.4709\n",
            "Epoch [22/75], Train Loss: 0.3880, Val Loss: 0.5070\n",
            "Epoch [23/75], Train Loss: 0.3941, Val Loss: 0.4595\n",
            "Epoch [24/75], Train Loss: 0.3852, Val Loss: 0.4381\n",
            "Epoch [25/75], Train Loss: 0.3587, Val Loss: 0.4797\n",
            "Epoch [26/75], Train Loss: 0.3742, Val Loss: 0.4253\n",
            "Epoch [27/75], Train Loss: 0.3726, Val Loss: 0.4790\n",
            "Epoch [28/75], Train Loss: 0.3570, Val Loss: 0.4941\n",
            "Epoch [29/75], Train Loss: 0.3517, Val Loss: 0.4852\n",
            "Epoch [30/75], Train Loss: 0.3553, Val Loss: 0.4840\n",
            "Epoch [31/75], Train Loss: 0.3503, Val Loss: 0.4314\n",
            "Epoch [32/75], Train Loss: 0.3326, Val Loss: 0.3627\n",
            "Epoch [33/75], Train Loss: 0.3284, Val Loss: 0.4875\n",
            "Epoch [34/75], Train Loss: 0.3187, Val Loss: 0.4447\n",
            "Epoch [35/75], Train Loss: 0.3304, Val Loss: 0.4570\n",
            "Epoch [36/75], Train Loss: 0.3164, Val Loss: 0.4183\n",
            "Epoch [37/75], Train Loss: 0.3167, Val Loss: 0.4577\n",
            "Epoch [38/75], Train Loss: 0.3224, Val Loss: 0.4152\n",
            "Epoch [39/75], Train Loss: 0.3174, Val Loss: 0.4330\n",
            "Epoch [40/75], Train Loss: 0.3066, Val Loss: 0.4161\n",
            "Epoch [41/75], Train Loss: 0.3225, Val Loss: 0.4582\n",
            "Epoch [42/75], Train Loss: 0.2963, Val Loss: 0.4132\n",
            "Epoch [43/75], Train Loss: 0.2932, Val Loss: 0.4081\n",
            "Epoch [44/75], Train Loss: 0.3071, Val Loss: 0.3885\n",
            "Epoch [45/75], Train Loss: 0.3025, Val Loss: 0.4801\n",
            "Epoch [46/75], Train Loss: 0.2853, Val Loss: 0.4726\n",
            "Epoch [47/75], Train Loss: 0.2818, Val Loss: 0.4350\n",
            "Epoch [48/75], Train Loss: 0.2928, Val Loss: 0.4450\n",
            "Epoch [49/75], Train Loss: 0.2876, Val Loss: 0.3809\n",
            "Epoch [50/75], Train Loss: 0.2709, Val Loss: 0.4194\n",
            "Epoch [51/75], Train Loss: 0.2704, Val Loss: 0.4320\n",
            "Epoch [52/75], Train Loss: 0.2712, Val Loss: 0.4646\n",
            "Epoch [53/75], Train Loss: 0.2971, Val Loss: 0.4995\n",
            "Epoch [54/75], Train Loss: 0.2590, Val Loss: 0.4021\n",
            "Epoch [55/75], Train Loss: 0.2590, Val Loss: 0.4032\n",
            "Epoch [56/75], Train Loss: 0.2620, Val Loss: 0.4689\n",
            "Epoch [57/75], Train Loss: 0.2515, Val Loss: 0.4154\n",
            "Epoch [58/75], Train Loss: 0.2657, Val Loss: 0.4251\n",
            "Epoch [59/75], Train Loss: 0.2533, Val Loss: 0.4663\n",
            "Epoch [60/75], Train Loss: 0.2696, Val Loss: 0.4334\n",
            "Epoch [61/75], Train Loss: 0.2518, Val Loss: 0.4510\n",
            "Epoch [62/75], Train Loss: 0.2520, Val Loss: 0.5229\n",
            "Epoch [63/75], Train Loss: 0.2503, Val Loss: 0.5038\n",
            "Epoch [64/75], Train Loss: 0.2537, Val Loss: 0.4661\n",
            "Epoch [65/75], Train Loss: 0.2479, Val Loss: 0.4931\n",
            "Epoch [66/75], Train Loss: 0.2388, Val Loss: 0.4406\n",
            "Epoch [67/75], Train Loss: 0.2583, Val Loss: 0.4390\n",
            "Epoch [68/75], Train Loss: 0.2385, Val Loss: 0.4158\n",
            "Epoch [69/75], Train Loss: 0.2408, Val Loss: 0.4540\n",
            "Epoch [70/75], Train Loss: 0.2406, Val Loss: 0.4780\n",
            "Epoch [71/75], Train Loss: 0.2468, Val Loss: 0.4270\n",
            "Epoch [72/75], Train Loss: 0.2384, Val Loss: 0.5314\n",
            "Epoch [73/75], Train Loss: 0.2385, Val Loss: 0.4637\n",
            "Epoch [74/75], Train Loss: 0.2306, Val Loss: 0.3852\n",
            "Epoch [75/75], Train Loss: 0.2344, Val Loss: 0.4984\n",
            "Training completed.\n",
            "\n",
            "Starting model evaluation...\n",
            "\n",
            "Starting model evaluation...\n",
            "Testing Dataset Information:\n",
            "Number of sequences: 4\n",
            "Model Sequence length: 200\n",
            "Evaluating:   0% 0/4 [00:00<?, ?it/s]\n",
            "Sequence: data5/imu1.csv\n",
            "MAE: 0.4110\n",
            "MSE: 0.4861\n",
            "Evaluating:  25% 1/4 [00:49<02:29, 49.71s/it]\n",
            "Sequence: data5/imu2.csv\n",
            "MAE: 0.3820\n",
            "MSE: 0.4454\n",
            "Evaluating:  50% 2/4 [02:25<02:33, 76.52s/it]\n",
            "Sequence: data5/imu3.csv\n",
            "MAE: 0.3981\n",
            "MSE: 0.4473\n",
            "Evaluating:  75% 3/4 [03:54<01:22, 82.67s/it]\n",
            "Sequence: data5/imu4.csv\n",
            "MAE: 0.3848\n",
            "MSE: 0.4255\n",
            "Evaluating: 100% 4/4 [04:53<00:00, 73.36s/it]\n",
            "\n",
            "Overall Test Loss: 0.4489\n",
            "Predictions shape: (183042, 3)\n",
            "Targets shape: (183042, 3)\n",
            "\n",
            "Overall Mean Squared Error: 0.4489\n",
            "Overall Mean Absolute Error: 0.3924\n",
            "Test results logged to TensorBoard in ../../transformer_logs/20240809-055025_d_model64_nhead4_layers3_ff512_output3_batch32_dropout0.5_sequencelength200_poolinglast_returnallFalse\n"
          ]
        }
      ],
      "source": [
        "# Baseline configuration\n",
        "!python transformer_train.py --d_model 32 --nhead 2 --num_layers 1 --dim_feedforward 128 --batch_size 64 --num_epochs 50 --pooling last\n",
        "\n",
        "# Deeper model configurations\n",
        "!python transformer_train.py --d_model 64 --nhead 4 --num_layers 2 --dim_feedforward 256 --batch_size 32 --num_epochs 25 --pooling last\n",
        "!python transformer_train.py --d_model 64 --nhead 4 --num_layers 6 --dim_feedforward 256 --batch_size 32 --num_epochs 25 --pooling last\n",
        "\n",
        "# Wider model configurations\n",
        "!python transformer_train.py --d_model 128 --nhead 8 --num_layers 2 --dim_feedforward 1024 --batch_size 16 --num_epochs 50 --dropout_rate 0.2 --pooling last\n",
        "!python transformer_train.py --d_model 128 --nhead 8 --num_layers 2 --dim_feedforward 1024 --batch_size 16 --num_epochs 50 --dropout_rate 0.3 --pooling last\n",
        "\n",
        "# Mean pooling configuration\n",
        "!python transformer_train.py --d_model 64 --nhead 4 --num_layers 2 --dim_feedforward 256 --batch_size 32 --num_epochs 50 --dropout_rate 0.2 --pooling mean\n",
        "\n",
        "# Return all positions configuration\n",
        "!python transformer_train.py --d_model 64 --nhead 4 --num_layers 2 --dim_feedforward 256 --batch_size 32 --num_epochs 50 --dropout_rate 0.2 --pooling last --return_all_positions\n",
        "\n",
        "# Larger batch size configuration\n",
        "!python transformer_train.py --d_model 64 --nhead 4 --num_layers 2 --dim_feedforward 256 --batch_size 128 --num_epochs 30 --dropout_rate 0.2 --pooling last\n",
        "\n",
        "# Higher dropout configuration\n",
        "!python transformer_train.py --d_model 64 --nhead 4 --num_layers 3 --dim_feedforward 512 --batch_size 32 --num_epochs 75 --dropout_rate 0.5 --pooling last\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VnVBqnUC791x",
        "outputId": "82a18296-4382-49d0-abda-458bde3ff2d8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n",
            "Total training samples: 3025\n",
            "Total validation samples: 462\n",
            "Total samples: 3487\n",
            "Input shape: torch.Size([200, 15])\n",
            "Target shape: torch.Size([3])\n",
            "Number of training batches: 48\n",
            "Number of validation batches: 8\n",
            "Performing mean baseline evaluation...\n",
            "Baseline Train Loss: 1.5231, Baseline Val Loss: 1.5008\n",
            "Epoch [1/40], Train Loss: 1.7201, Val Loss: 0.9011\n",
            "Epoch [2/40], Train Loss: 0.8152, Val Loss: 0.7854\n",
            "Epoch [3/40], Train Loss: 0.6172, Val Loss: 0.5041\n",
            "Epoch [4/40], Train Loss: 0.5518, Val Loss: 0.4895\n",
            "Epoch [5/40], Train Loss: 0.5339, Val Loss: 0.5072\n",
            "Epoch [6/40], Train Loss: 0.4855, Val Loss: 0.4444\n",
            "Epoch [7/40], Train Loss: 0.4667, Val Loss: 0.5554\n",
            "Epoch [8/40], Train Loss: 0.4554, Val Loss: 0.4965\n",
            "Epoch [9/40], Train Loss: 0.4447, Val Loss: 0.4560\n",
            "Epoch [10/40], Train Loss: 0.3973, Val Loss: 0.4463\n",
            "Epoch [11/40], Train Loss: 0.3937, Val Loss: 0.4115\n",
            "Epoch [12/40], Train Loss: 0.3866, Val Loss: 0.4673\n",
            "Epoch [13/40], Train Loss: 0.3613, Val Loss: 0.3708\n",
            "Epoch [14/40], Train Loss: 0.3446, Val Loss: 0.3371\n",
            "Epoch [15/40], Train Loss: 0.3275, Val Loss: 0.3637\n",
            "Epoch [16/40], Train Loss: 0.3271, Val Loss: 0.3576\n",
            "Epoch [17/40], Train Loss: 0.2990, Val Loss: 0.3523\n",
            "Epoch [18/40], Train Loss: 0.2925, Val Loss: 0.3614\n",
            "Epoch [19/40], Train Loss: 0.2844, Val Loss: 0.3398\n",
            "Epoch [20/40], Train Loss: 0.2783, Val Loss: 0.3529\n",
            "Epoch [21/40], Train Loss: 0.2609, Val Loss: 0.2859\n",
            "Epoch [22/40], Train Loss: 0.2456, Val Loss: 0.3557\n",
            "Epoch [23/40], Train Loss: 0.2445, Val Loss: 0.3382\n",
            "Epoch [24/40], Train Loss: 0.2378, Val Loss: 0.3748\n",
            "Epoch [25/40], Train Loss: 0.2442, Val Loss: 0.3014\n",
            "Epoch [26/40], Train Loss: 0.2187, Val Loss: 0.3367\n",
            "Epoch [27/40], Train Loss: 0.2119, Val Loss: 0.3160\n",
            "Epoch [28/40], Train Loss: 0.2076, Val Loss: 0.3427\n",
            "Epoch [29/40], Train Loss: 0.2086, Val Loss: 0.4021\n",
            "Epoch [30/40], Train Loss: 0.1984, Val Loss: 0.3131\n",
            "Epoch [31/40], Train Loss: 0.1899, Val Loss: 0.3565\n",
            "Epoch [32/40], Train Loss: 0.1910, Val Loss: 0.3488\n",
            "Epoch [33/40], Train Loss: 0.1790, Val Loss: 0.3346\n",
            "Epoch [34/40], Train Loss: 0.1775, Val Loss: 0.3463\n",
            "Epoch [35/40], Train Loss: 0.1764, Val Loss: 0.3998\n",
            "Epoch [36/40], Train Loss: 0.1658, Val Loss: 0.2974\n",
            "Epoch [37/40], Train Loss: 0.1689, Val Loss: 0.3918\n",
            "Epoch [38/40], Train Loss: 0.1700, Val Loss: 0.3101\n",
            "Epoch [39/40], Train Loss: 0.1568, Val Loss: 0.3347\n",
            "Epoch [40/40], Train Loss: 0.1638, Val Loss: 0.3839\n",
            "Training completed.\n",
            "\n",
            "Starting model evaluation...\n",
            "\n",
            "Starting model evaluation...\n",
            "Testing Dataset Information:\n",
            "Number of sequences: 4\n",
            "Model Sequence length: 200\n",
            "Evaluating:   0% 0/4 [00:00<?, ?it/s]\n",
            "Sequence: data5/imu1.csv\n",
            "MAE: 0.3862\n",
            "MSE: 0.4290\n",
            "Evaluating:  25% 1/4 [00:49<02:27, 49.08s/it]\n",
            "Sequence: data5/imu2.csv\n",
            "MAE: 0.3474\n",
            "MSE: 0.3507\n",
            "Evaluating:  50% 2/4 [02:24<02:32, 76.14s/it]\n",
            "Sequence: data5/imu3.csv\n",
            "MAE: 0.3484\n",
            "MSE: 0.3377\n",
            "Evaluating:  75% 3/4 [03:53<01:22, 82.15s/it]\n",
            "Sequence: data5/imu4.csv\n",
            "MAE: 0.3311\n",
            "MSE: 0.3270\n",
            "Evaluating: 100% 4/4 [04:51<00:00, 72.78s/it]\n",
            "\n",
            "Overall Test Loss: 0.3553\n",
            "Predictions shape: (183042, 3)\n",
            "Targets shape: (183042, 3)\n",
            "\n",
            "Overall Mean Squared Error: 0.3553\n",
            "Overall Mean Absolute Error: 0.3510\n",
            "Test results logged to TensorBoard in ../../transformer_logs/20240809-082751_d_model96_nhead6_layers3_ff384_output3_batch64_dropout0.15_sequencelength200_poolinglast_returnallFalse\n",
            "Using device: cuda\n",
            "Total training samples: 3025\n",
            "Total validation samples: 462\n",
            "Total samples: 3487\n",
            "Input shape: torch.Size([200, 15])\n",
            "Target shape: torch.Size([3])\n",
            "Number of training batches: 190\n",
            "Number of validation batches: 29\n",
            "Performing mean baseline evaluation...\n",
            "Baseline Train Loss: 1.5231, Baseline Val Loss: 1.5008\n",
            "Epoch [1/50], Train Loss: 1.3005, Val Loss: 0.7209\n",
            "Epoch [2/50], Train Loss: 0.6164, Val Loss: 0.5078\n",
            "Epoch [3/50], Train Loss: 0.5425, Val Loss: 0.9938\n",
            "Epoch [4/50], Train Loss: 0.5110, Val Loss: 0.4751\n",
            "Epoch [5/50], Train Loss: 0.4534, Val Loss: 0.4952\n",
            "Epoch [6/50], Train Loss: 0.4217, Val Loss: 0.4602\n",
            "Epoch [7/50], Train Loss: 0.3683, Val Loss: 0.4311\n",
            "Epoch [8/50], Train Loss: 0.3521, Val Loss: 0.3842\n",
            "Epoch [9/50], Train Loss: 0.3387, Val Loss: 0.3452\n",
            "Epoch [10/50], Train Loss: 0.3139, Val Loss: 0.3705\n",
            "Epoch [11/50], Train Loss: 0.3182, Val Loss: 0.3780\n",
            "Epoch [12/50], Train Loss: 0.2971, Val Loss: 0.3339\n",
            "Epoch [13/50], Train Loss: 0.2859, Val Loss: 0.3131\n",
            "Epoch [14/50], Train Loss: 0.2719, Val Loss: 0.3089\n",
            "Epoch [15/50], Train Loss: 0.2744, Val Loss: 0.4191\n",
            "Epoch [16/50], Train Loss: 0.2618, Val Loss: 0.3642\n",
            "Epoch [17/50], Train Loss: 0.2446, Val Loss: 0.3474\n",
            "Epoch [18/50], Train Loss: 0.2313, Val Loss: 0.3442\n",
            "Epoch [19/50], Train Loss: 0.2344, Val Loss: 0.3277\n",
            "Epoch [20/50], Train Loss: 0.2190, Val Loss: 0.3434\n",
            "Epoch [21/50], Train Loss: 0.2269, Val Loss: 0.3304\n",
            "Epoch [22/50], Train Loss: 0.2283, Val Loss: 0.3185\n",
            "Epoch [23/50], Train Loss: 0.2175, Val Loss: 0.3210\n",
            "Epoch [24/50], Train Loss: 0.2150, Val Loss: 0.3171\n",
            "Epoch [25/50], Train Loss: 0.2066, Val Loss: 0.4058\n",
            "Epoch [26/50], Train Loss: 0.2094, Val Loss: 0.3022\n",
            "Epoch [27/50], Train Loss: 0.2092, Val Loss: 0.3527\n",
            "Epoch [28/50], Train Loss: 0.1870, Val Loss: 0.2835\n",
            "Epoch [29/50], Train Loss: 0.1838, Val Loss: 0.3134\n",
            "Epoch [30/50], Train Loss: 0.1862, Val Loss: 0.3990\n",
            "Epoch [31/50], Train Loss: 0.1833, Val Loss: 0.4404\n",
            "Epoch [32/50], Train Loss: 0.1767, Val Loss: 0.3635\n",
            "Epoch [33/50], Train Loss: 0.1733, Val Loss: 0.3271\n",
            "Epoch [34/50], Train Loss: 0.1619, Val Loss: 0.3583\n",
            "Epoch [35/50], Train Loss: 0.1672, Val Loss: 0.3217\n",
            "Epoch [36/50], Train Loss: 0.1654, Val Loss: 0.4371\n",
            "Epoch [37/50], Train Loss: 0.1577, Val Loss: 0.3663\n",
            "Epoch [38/50], Train Loss: 0.1619, Val Loss: 0.4083\n",
            "Epoch [39/50], Train Loss: 0.1587, Val Loss: 0.3504\n",
            "Epoch [40/50], Train Loss: 0.1593, Val Loss: 0.3205\n",
            "Epoch [41/50], Train Loss: 0.1523, Val Loss: 0.3452\n",
            "Epoch [42/50], Train Loss: 0.1472, Val Loss: 0.3154\n",
            "Epoch [43/50], Train Loss: 0.1479, Val Loss: 0.3595\n",
            "Epoch [44/50], Train Loss: 0.1489, Val Loss: 0.3776\n",
            "Epoch [45/50], Train Loss: 0.1569, Val Loss: 0.3512\n",
            "Epoch [46/50], Train Loss: 0.1544, Val Loss: 0.3891\n",
            "Epoch [47/50], Train Loss: 0.1316, Val Loss: 0.3813\n",
            "Epoch [48/50], Train Loss: 0.1399, Val Loss: 0.3815\n",
            "Epoch [49/50], Train Loss: 0.1324, Val Loss: 0.4337\n",
            "Epoch [50/50], Train Loss: 0.1331, Val Loss: 0.3664\n",
            "Training completed.\n",
            "\n",
            "Starting model evaluation...\n",
            "\n",
            "Starting model evaluation...\n",
            "Testing Dataset Information:\n",
            "Number of sequences: 4\n",
            "Model Sequence length: 200\n",
            "Evaluating:   0% 0/4 [00:00<?, ?it/s]\n",
            "Sequence: data5/imu1.csv\n",
            "MAE: 0.3502\n",
            "MSE: 0.3724\n",
            "Evaluating:  25% 1/4 [00:39<01:58, 39.36s/it]\n",
            "Sequence: data5/imu2.csv\n",
            "MAE: 0.3165\n",
            "MSE: 0.3292\n",
            "Evaluating:  50% 2/4 [01:54<02:00, 60.46s/it]\n",
            "Sequence: data5/imu3.csv\n",
            "MAE: 0.2967\n",
            "MSE: 0.2676\n",
            "Evaluating:  75% 3/4 [03:05<01:05, 65.45s/it]\n",
            "Sequence: data5/imu4.csv\n",
            "MAE: 0.2890\n",
            "MSE: 0.2630\n",
            "Evaluating: 100% 4/4 [03:52<00:00, 58.14s/it]\n",
            "\n",
            "Overall Test Loss: 0.3045\n",
            "Predictions shape: (183042, 3)\n",
            "Targets shape: (183042, 3)\n",
            "\n",
            "Overall Mean Squared Error: 0.3045\n",
            "Overall Mean Absolute Error: 0.3107\n",
            "Test results logged to TensorBoard in ../../transformer_logs/20240809-083330_d_model192_nhead12_layers2_ff768_output3_batch16_dropout0.1_sequencelength200_poolinglast_returnallFalse\n",
            "usage: transformer_train.py [-h] [--root_dir ROOT_DIR] [--sequence_length SEQUENCE_LENGTH]\n",
            "                            [--input_size INPUT_SIZE] [--d_model D_MODEL] [--nhead NHEAD]\n",
            "                            [--num_layers NUM_LAYERS] [--dim_feedforward DIM_FEEDFORWARD]\n",
            "                            [--output_size OUTPUT_SIZE] [--learning_rate LEARNING_RATE]\n",
            "                            [--batch_size BATCH_SIZE] --num_epochs NUM_EPOCHS\n",
            "                            [--dropout_rate DROPOUT_RATE] [--model_save_path MODEL_SAVE_PATH]\n",
            "                            [--test_root_dir TEST_ROOT_DIR] [--pooling {last,mean}]\n",
            "                            [--return_all_positions]\n",
            "transformer_train.py: error: unrecognized arguments: --residual_connections\n",
            "usage: transformer_train.py [-h] [--root_dir ROOT_DIR] [--sequence_length SEQUENCE_LENGTH]\n",
            "                            [--input_size INPUT_SIZE] [--d_model D_MODEL] [--nhead NHEAD]\n",
            "                            [--num_layers NUM_LAYERS] [--dim_feedforward DIM_FEEDFORWARD]\n",
            "                            [--output_size OUTPUT_SIZE] [--learning_rate LEARNING_RATE]\n",
            "                            [--batch_size BATCH_SIZE] --num_epochs NUM_EPOCHS\n",
            "                            [--dropout_rate DROPOUT_RATE] [--model_save_path MODEL_SAVE_PATH]\n",
            "                            [--test_root_dir TEST_ROOT_DIR] [--pooling {last,mean}]\n",
            "                            [--return_all_positions]\n",
            "transformer_train.py: error: argument --pooling: invalid choice: 'ensemble' (choose from 'last', 'mean')\n"
          ]
        }
      ],
      "source": [
        "# Standard model training\n",
        "!python transformer_train.py --d_model 96 --nhead 6 --num_layers 3 --dim_feedforward 384 --batch_size 64 --num_epochs 40 --dropout_rate 0.15 --pooling last\n",
        "\n",
        "# Wide but shallow model\n",
        "!python transformer_train.py --d_model 192 --nhead 12 --num_layers 2 --dim_feedforward 768 --batch_size 16 --num_epochs 50 --dropout_rate 0.1 --pooling last\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **Other Experiments**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GfpO4ynDDo7B"
      },
      "outputs": [],
      "source": [
        "%cd /\n",
        "!ls\n",
        "%cd content\n",
        "%cd indoor_localization_oxford_dataset\n",
        "%cd src\n",
        "%cd other_exp\n",
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nNER_W2wDo92"
      },
      "outputs": [],
      "source": [
        "!python lstm_train.py --sequence_length 400 --hidden_sizes 64 --num_epochs 80 --dropout_rate 0.4 --input_size 12\n",
        "!python lstm_train.py --sequence_length 400 --hidden_sizes 32 --num_epochs 80 --dropout_rate 0.4 --input_size 12\n",
        "!python lstm_train.py --sequence_length 400 --hidden_sizes 128 --num_epochs 80 --dropout_rate 0.4 --input_size 12"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **ResNet**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cqnEQ-9UqUCa"
      },
      "outputs": [],
      "source": [
        "%cd /\n",
        "!ls\n",
        "%cd content\n",
        "%cd indoor_localization_oxford_dataset\n",
        "%cd src\n",
        "%cd easy_resnet\n",
        "!ls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Dummy Run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qv5-Xgl37-g4"
      },
      "outputs": [],
      "source": [
        "!python resnet_train.py --num_epochs 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python resnet_train.py --sequence_length 200 --input_size 12 --channels 64 128 256 --output_size 3 --learning_rate 0.001 --batch_size 32 --num_epochs 50 --dropout_rate 0.3\n",
        "\n",
        "# Dropout Increase\n",
        "!python resnet_train.py --sequence_length 200 --input_size 12 --channels 64 128 256 --output_size 3 --learning_rate 0.001 --batch_size 32 --num_epochs 50 --dropout_rate 0.4\n",
        "\n",
        "# Longer sequence length\n",
        "!python resnet_train.py --sequence_length 300 --input_size 12 --channels 64 128 256 --output_size 3 --learning_rate 0.001 --batch_size 32 --num_epochs 50 --dropout_rate 0.3\n",
        "\n",
        "# Larger batch size\n",
        "!python resnet_train.py --sequence_length 200 --input_size 12 --channels 64 128 256 --output_size 3 --learning_rate 0.001 --batch_size 64 --num_epochs 50 --dropout_rate 0.4\n",
        "\n",
        "# Smaller batch size\n",
        "!python resnet_train.py --sequence_length 200 --input_size 12 --channels 64 128 256 --output_size 3 --learning_rate 0.001 --batch_size 16 --num_epochs 50 --dropout_rate 0.4\n",
        "\n",
        "# Higher dropout rate\n",
        "!python resnet_train.py --sequence_length 200 --input_size 12 --channels 64 128 256 --output_size 3 --learning_rate 0.001 --batch_size 32 --num_epochs 50 --dropout_rate 0.5\n",
        "\n",
        "# Deeper network\n",
        "!python resnet_train.py --sequence_length 200 --input_size 12 --channels 64 128 256 512 --output_size 3 --learning_rate 0.001 --batch_size 32 --num_epochs 60 --dropout_rate 0.4\n",
        "\n",
        "# Wider network\n",
        "!python resnet_train.py --sequence_length 200 --input_size 12 --channels 128 256 512 --output_size 3 --learning_rate 0.001 --batch_size 32 --num_epochs 50 --dropout_rate 0.4\n",
        "\n",
        "# Shorter sequence length with larger batch size\n",
        "!python resnet_train.py --sequence_length 150 --input_size 12 --channels 64 128 256 --output_size 3 --learning_rate 0.001 --batch_size 128 --num_epochs 50 --dropout_rate 0.4\n",
        "\n",
        "# Longer sequence length with smaller learning rate\n",
        "!python resnet_train.py --sequence_length 400 --input_size 12 --channels 64 128 256 --output_size 3 --learning_rate 0.0002 --batch_size 32 --num_epochs 100 --dropout_rate 0.4\n",
        "\n",
        "# Shallow network with higher dropout\n",
        "!python resnet_train.py --sequence_length 200 --input_size 12 --channels 128 256 --output_size 3 --learning_rate 0.001 --batch_size 32 --num_epochs 60 --dropout_rate 0.6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v3Lwo-i-rm5c"
      },
      "outputs": [],
      "source": [
        " "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tw2KXwfzrm8P"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OcBwC4ADg23W",
        "outputId": "82c28b83-eed7-477a-c694-c41e12bdb1c3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content\n",
            "drive  indoor_localization_oxford_dataset  sample_data\n",
            "/content/indoor_localization_oxford_dataset\n",
            "data\t    docs\t\t\t\tREADME.md\t  transformer_logs\n",
            "data.zip.1  indoor_localization_oxford_dataset\trequirements.txt  transformer_logs.zip\n",
            "deprecated  model\t\t\t\tsrc\n"
          ]
        }
      ],
      "source": [
        "%cd /content\n",
        "!ls\n",
        "%cd indoor_localization_oxford_dataset\n",
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vZXm8f1vicOu",
        "outputId": "da2d88e6-d914-4018-b0ab-cf3fe3890397"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uo1s7F80rm-s",
        "outputId": "ff7bd1c2-6a5a-44af-9e7f-2c7f111b0809"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "updating: content/indoor_localization_oxford_dataset/transformer_logs/ (stored 0%)\n",
            "  adding: content/indoor_localization_oxford_dataset/transformer_logs/20240809-083330_d_model192_nhead12_layers2_ff768_output3_batch16_dropout0.1_sequencelength200_poolinglast_returnallFalse/ (stored 0%)\n",
            "  adding: content/indoor_localization_oxford_dataset/transformer_logs/20240809-083330_d_model192_nhead12_layers2_ff768_output3_batch16_dropout0.1_sequencelength200_poolinglast_returnallFalse/events.out.tfevents.1723192410.666c55fafbc8.16975.0 (deflated 63%)\n",
            "  adding: content/indoor_localization_oxford_dataset/transformer_logs/.ipynb_checkpoints/ (stored 0%)\n",
            "  adding: content/indoor_localization_oxford_dataset/transformer_logs/20240809-082751_d_model96_nhead6_layers3_ff384_output3_batch64_dropout0.15_sequencelength200_poolinglast_returnallFalse/ (stored 0%)\n",
            "  adding: content/indoor_localization_oxford_dataset/transformer_logs/20240809-082751_d_model96_nhead6_layers3_ff384_output3_batch64_dropout0.15_sequencelength200_poolinglast_returnallFalse/events.out.tfevents.1723192071.666c55fafbc8.15488.0 (deflated 62%)\n"
          ]
        }
      ],
      "source": [
        "!zip -r  /content/indoor_localization_oxford_dataset/transformer_logs.zip  /content/indoor_localization_oxford_dataset/transformer_logs\n",
        "!cp   /content/indoor_localization_oxford_dataset/transformer_logs.zip /content/drive/MyDrive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NRBbVtcJtmK8"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
