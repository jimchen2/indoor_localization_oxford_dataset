{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Import**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import random\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import shutil\n",
    "from ipywidgets import interact, fixed\n",
    "from ipywidgets import widgets\n",
    "from ipywidgets import interactive, widgets\n",
    "from IPython.display import display\n",
    "from ipywidgets import interactive, widgets, HBox, VBox\n",
    "\n",
    "from datetime import datetime\n",
    "import socket\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"Using GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Proprocess Data to Raw Data for Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PIXEL_TO_METER_SCALE = 13.913\n",
    "image = Image.open(\"data/map/hkust_4f.jpg\")\n",
    "image = image.resize((int(image.size[0] / PIXEL_TO_METER_SCALE), \n",
    "                      int(image.size[1] / PIXEL_TO_METER_SCALE))).transpose(Image.FLIP_TOP_BOTTOM)\n",
    "\n",
    "def process_csv_file(csv_path, image_size, pixel_to_meter_scale):\n",
    "    path_data = {'x':[], 'y':[], \"Bv\":[], \"Bh\":[], \"Bp\":[]}\n",
    "    \n",
    "    with open(csv_path, 'r') as file:\n",
    "        reader = csv.reader(file)\n",
    "        header = next(reader)  # Skip the header\n",
    "        \n",
    "        for row in reader:\n",
    "            x = float(row[3]) / pixel_to_meter_scale\n",
    "            y = - float(row[4]) / pixel_to_meter_scale + image_size[1]\n",
    "            Bv = float(row[0])\n",
    "            Bh = float(row[1])\n",
    "            Bp = float(row[2])\n",
    "            \n",
    "            path_data[\"x\"].append(x)\n",
    "            path_data[\"y\"].append(y)\n",
    "            path_data[\"Bv\"].append(Bv)\n",
    "            path_data[\"Bh\"].append(Bh)\n",
    "            path_data[\"Bp\"].append(Bp)\n",
    "    \n",
    "    return path_data\n",
    "\n",
    "\n",
    "train_raw_data = []\n",
    "data_path = os.path.join(\".\", \"data\", \"formatted\", \"HKUST_4F\", \"training data\")\n",
    "\n",
    "for root, _, files in os.walk(data_path):\n",
    "    for file in files:\n",
    "        if file.endswith('.csv'):\n",
    "            train_raw_data.append(process_csv_file(os.path.join(root, file), image.size, PIXEL_TO_METER_SCALE))\n",
    "\n",
    "test_raw_data = []\n",
    "test_data_path = os.path.join(\".\", \"data\", \"formatted\", \"HKUST_4F\", \"testing data\")\n",
    "\n",
    "for root, _, files in os.walk(test_data_path):\n",
    "    for file in files:\n",
    "        if file.endswith('.csv'):\n",
    "            test_raw_data.append(process_csv_file(os.path.join(root, file), image.size, PIXEL_TO_METER_SCALE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Length of the Raw Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Raw data:\n",
      "  Total length: 176585\n",
      "  Individual lengths: [703, 763, 740, 675, 687, 710, 682, 713, 705, 700, 736, 745, 759, 692, 646, 666, 669, 665, 690, 686, 645, 643, 677, 677, 660, 625, 678, 685, 4239, 4414, 4350, 4291, 4302, 4330, 4339, 4296, 4294, 4314, 4489, 4318, 4373, 4422, 5732, 6268, 5454, 5714, 5604, 5563, 6572, 5592, 6119, 5822, 5412, 5503, 6328, 5713, 5611, 682, 680, 710, 685, 672, 665, 649, 673, 684, 686, 670, 685, 680, 664]\n",
      "  Number of trajectories: 71\n",
      "\n",
      "Test Raw data:\n",
      "  Total length: 18017\n",
      "  Individual lengths: [750, 4313, 681, 658, 4282, 662, 5958, 713]\n",
      "  Number of trajectories: 8\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def print_data_info(data, name):\n",
    "    total_length = sum(len(d['x']) for d in data)\n",
    "    individual_lengths = [len(d['x']) for d in data]\n",
    "    num_trajectories = len(data)\n",
    "    \n",
    "    print(f\"{name} data:\")\n",
    "    print(f\"  Total length: {total_length}\")\n",
    "    print(f\"  Individual lengths: {individual_lengths}\")\n",
    "    print(f\"  Number of trajectories: {num_trajectories}\")\n",
    "    print()\n",
    "\n",
    "\n",
    "print_data_info(train_raw_data, \"Train Raw\")\n",
    "print_data_info(test_raw_data, \"Test Raw\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Process Data to Sequences**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (140700, 10, 3) (140700, 2)\n",
      "Validation data shape: (35175, 10, 3) (35175, 2)\n",
      "Testing data shape: (17937, 10, 3) (17937, 2)\n"
     ]
    }
   ],
   "source": [
    "def prepare_sequences(data, sequence_length):\n",
    "    X, y = [], []\n",
    "    for traj in data:\n",
    "        input_seq = np.column_stack((traj['Bv'], traj['Bh'], traj['Bp']))\n",
    "        output_seq = np.column_stack((traj['x'], traj['y']))\n",
    "        \n",
    "        for i in range(len(input_seq) - sequence_length):\n",
    "            X.append(input_seq[i:i+sequence_length])\n",
    "            y.append(output_seq[i+sequence_length])\n",
    "    \n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# Set sequence length\n",
    "sequence_length = 10\n",
    "\n",
    "# Prepare training data\n",
    "X_train_val, y_train_val = prepare_sequences(train_raw_data, sequence_length)\n",
    "\n",
    "# Split training data into train and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.2, random_state=42)\n",
    "\n",
    "# Prepare test data\n",
    "X_test, y_test = prepare_sequences(test_raw_data, sequence_length)\n",
    "\n",
    "# Normalize input data\n",
    "scaler_X = StandardScaler()\n",
    "X_train_scaled = scaler_X.fit_transform(X_train.reshape(-1, X_train.shape[-1])).reshape(X_train.shape)\n",
    "X_val_scaled = scaler_X.transform(X_val.reshape(-1, X_val.shape[-1])).reshape(X_val.shape)\n",
    "X_test_scaled = scaler_X.transform(X_test.reshape(-1, X_test.shape[-1])).reshape(X_test.shape)\n",
    "\n",
    "# Normalize output data\n",
    "scaler_y = StandardScaler()\n",
    "y_train_scaled = scaler_y.fit_transform(y_train)\n",
    "y_val_scaled = scaler_y.transform(y_val)\n",
    "y_test_scaled = scaler_y.transform(y_test)\n",
    "\n",
    "print(\"Training data shape:\", X_train_scaled.shape, y_train_scaled.shape)\n",
    "print(\"Validation data shape:\", X_val_scaled.shape, y_val_scaled.shape)\n",
    "print(\"Testing data shape:\", X_test_scaled.shape, y_test_scaled.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Plot and Visualize Windows**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6ffda8edfb847c89867ec37234193a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h3>Train Dataset</h3>'), IntSlider(value=0, description='Train Index:', max=140699…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd3bf382071b40b686a1ae468609c52c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h3>Validation Dataset</h3>'), IntSlider(value=0, description='Validation Index:', …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32f887cab9f042c487328629eea7e165",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h3>Test Dataset</h3>'), IntSlider(value=0, description='Test Index:', max=17936), …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_single_dataset(index, data_type, dataset):\n",
    "    plt.figure(figsize=(15, 5))\n",
    "\n",
    "    if data_type == 'Raw':\n",
    "        X = X_train if dataset == 'Train' else X_val if dataset == 'Validation' else X_test\n",
    "        y = y_train if dataset == 'Train' else y_val if dataset == 'Validation' else y_test\n",
    "    else:\n",
    "        X = X_train_scaled if dataset == 'Train' else X_val_scaled if dataset == 'Validation' else X_test_scaled\n",
    "        y = y_train_scaled if dataset == 'Train' else y_val_scaled if dataset == 'Validation' else y_test_scaled\n",
    "\n",
    "    # Plot input sequence\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.title(f'{data_type} Input Sequence - {dataset}')\n",
    "    plt.plot(X[index, :, 0], label='Bv')\n",
    "    plt.plot(X[index, :, 1], label='Bh')\n",
    "    plt.plot(X[index, :, 2], label='Bp')\n",
    "    plt.legend()\n",
    "    plt.xlabel('Steps')\n",
    "    plt.ylabel('Value')\n",
    "\n",
    "    # Plot output\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.title(f'{data_type} Output - {dataset}')\n",
    "    plt.scatter(y[index, 0], y[index, 1], color='red', label='Position')\n",
    "    plt.legend()\n",
    "    plt.xlabel('X')\n",
    "    plt.ylabel('Y')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Create widgets and interactive plots for each dataset\n",
    "def create_interactive_plot(dataset):\n",
    "    index_widget = widgets.IntSlider(\n",
    "        min=0, \n",
    "        max=len(X_train)-1 if dataset == 'Train' else len(X_val)-1 if dataset == 'Validation' else len(X_test)-1, \n",
    "        description=f'{dataset} Index:'\n",
    "    )\n",
    "    data_type_widget = widgets.RadioButtons(options=['Raw', 'Scaled'], description='Data Type:')\n",
    "    \n",
    "    interactive_plot = interactive(\n",
    "        plot_single_dataset, \n",
    "        index=index_widget, \n",
    "        data_type=data_type_widget, \n",
    "        dataset=widgets.fixed(dataset)\n",
    "    )\n",
    "    \n",
    "    return VBox([widgets.HTML(f\"<h3>{dataset} Dataset</h3>\"), index_widget, data_type_widget, interactive_plot.children[-1]])\n",
    "\n",
    "# Create and display interactive plots for each dataset\n",
    "train_plot = create_interactive_plot('Train')\n",
    "val_plot = create_interactive_plot('Validation')\n",
    "test_plot = create_interactive_plot('Test')\n",
    "\n",
    "display(train_plot, val_plot, test_plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Define the dataset and dataloader**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrajectoryDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.FloatTensor(X)\n",
    "        self.y = torch.FloatTensor(y)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = TrajectoryDataset(X_train_scaled, y_train_scaled)\n",
    "val_dataset = TrajectoryDataset(X_val_scaled, y_val_scaled)\n",
    "test_dataset = TrajectoryDataset(X_test_scaled, y_test_scaled)\n",
    "\n",
    "# Create dataloaders\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Define the RNN model**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrajectoryRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(TrajectoryRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.rnn = nn.GRU(input_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        _, hidden = self.rnn(x)\n",
    "        output = self.fc(hidden.squeeze(0))\n",
    "        return output\n",
    "\n",
    "# Initialize the model\n",
    "input_size = 3  # Bv, Bh, Bp\n",
    "hidden_size = 64\n",
    "output_size = 2  # x, y\n",
    "model = TrajectoryRNN(input_size, hidden_size, output_size).to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Train the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   0%|          | 0/50 [00:05<?, ?it/s, Epoch=1, Train Loss=0.9332, Val Loss=0.9099]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Train MSE: 1921.1167, MAE: 46.4252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   2%|▏         | 1/50 [00:07<06:04,  7.43s/it, Epoch=1, Train Loss=0.9332, Val Loss=0.9099]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Val MSE: 1905.9312, MAE: 46.3419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   2%|▏         | 1/50 [00:12<06:04,  7.43s/it, Epoch=2, Train Loss=0.8927, Val Loss=0.8838]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Train MSE: 1880.4971, MAE: 45.6342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   4%|▍         | 2/50 [00:14<05:55,  7.41s/it, Epoch=2, Train Loss=0.8927, Val Loss=0.8838]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Val MSE: 1866.4340, MAE: 45.5197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   4%|▍         | 2/50 [00:20<05:55,  7.41s/it, Epoch=3, Train Loss=0.8837, Val Loss=0.8786]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Train MSE: 1872.4192, MAE: 45.2958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   6%|▌         | 3/50 [00:22<05:50,  7.46s/it, Epoch=3, Train Loss=0.8837, Val Loss=0.8786]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Val MSE: 1860.6241, MAE: 45.1954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   6%|▌         | 3/50 [00:27<05:50,  7.46s/it, Epoch=4, Train Loss=0.8796, Val Loss=0.8775]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Train MSE: 1873.1370, MAE: 45.4040\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   8%|▊         | 4/50 [00:29<05:42,  7.44s/it, Epoch=4, Train Loss=0.8796, Val Loss=0.8775]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Val MSE: 1859.9151, MAE: 45.2893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   8%|▊         | 4/50 [00:34<05:42,  7.44s/it, Epoch=5, Train Loss=0.8771, Val Loss=0.8716]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Train MSE: 1861.2656, MAE: 45.0676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  10%|█         | 5/50 [00:37<05:36,  7.48s/it, Epoch=5, Train Loss=0.8771, Val Loss=0.8716]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Val MSE: 1849.9264, MAE: 44.9572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  10%|█         | 5/50 [00:42<05:36,  7.48s/it, Epoch=6, Train Loss=0.8747, Val Loss=0.8696]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Train MSE: 1855.6380, MAE: 45.1405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  12%|█▏        | 6/50 [00:44<05:29,  7.49s/it, Epoch=6, Train Loss=0.8747, Val Loss=0.8696]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Val MSE: 1844.1761, MAE: 45.0346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  12%|█▏        | 6/50 [00:50<05:29,  7.49s/it, Epoch=7, Train Loss=0.8725, Val Loss=0.8656]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Train MSE: 1849.2361, MAE: 44.9587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  14%|█▍        | 7/50 [00:52<05:24,  7.54s/it, Epoch=7, Train Loss=0.8725, Val Loss=0.8656]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Val MSE: 1836.6355, MAE: 44.8451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  14%|█▍        | 7/50 [00:58<05:24,  7.54s/it, Epoch=8, Train Loss=0.8699, Val Loss=0.8656]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Train MSE: 1852.9421, MAE: 44.7464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  16%|█▌        | 8/50 [01:00<05:19,  7.61s/it, Epoch=8, Train Loss=0.8699, Val Loss=0.8656]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Val MSE: 1841.4266, MAE: 44.6280\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  16%|█▌        | 8/50 [01:05<05:19,  7.61s/it, Epoch=9, Train Loss=0.8666, Val Loss=0.8608]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Train MSE: 1838.9079, MAE: 44.7463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  18%|█▊        | 9/50 [01:08<05:14,  7.68s/it, Epoch=9, Train Loss=0.8666, Val Loss=0.8608]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Val MSE: 1827.3714, MAE: 44.6613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  18%|█▊        | 9/50 [01:13<05:14,  7.68s/it, Epoch=10, Train Loss=0.8645, Val Loss=0.8631]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Train MSE: 1845.0334, MAE: 44.5573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  20%|██        | 10/50 [01:15<05:07,  7.69s/it, Epoch=10, Train Loss=0.8645, Val Loss=0.8631]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Val MSE: 1835.0354, MAE: 44.4603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  20%|██        | 10/50 [01:21<05:07,  7.69s/it, Epoch=11, Train Loss=0.8618, Val Loss=0.8595]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Train MSE: 1829.7410, MAE: 44.3224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  22%|██▏       | 11/50 [01:23<04:57,  7.63s/it, Epoch=11, Train Loss=0.8618, Val Loss=0.8595]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Val MSE: 1819.1692, MAE: 44.2423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  22%|██▏       | 11/50 [01:28<04:57,  7.63s/it, Epoch=12, Train Loss=0.8597, Val Loss=0.8564]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Train MSE: 1825.4915, MAE: 44.4909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  24%|██▍       | 12/50 [01:30<04:50,  7.64s/it, Epoch=12, Train Loss=0.8597, Val Loss=0.8564]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Val MSE: 1814.9754, MAE: 44.4192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  24%|██▍       | 12/50 [01:36<04:50,  7.64s/it, Epoch=13, Train Loss=0.8574, Val Loss=0.8519]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Train MSE: 1815.0106, MAE: 44.3510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  26%|██▌       | 13/50 [01:38<04:42,  7.64s/it, Epoch=13, Train Loss=0.8574, Val Loss=0.8519]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Val MSE: 1807.0593, MAE: 44.2871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  26%|██▌       | 13/50 [01:43<04:42,  7.64s/it, Epoch=14, Train Loss=0.8555, Val Loss=0.8519]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Train MSE: 1812.6318, MAE: 44.2261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  28%|██▊       | 14/50 [01:45<04:30,  7.52s/it, Epoch=14, Train Loss=0.8555, Val Loss=0.8519]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Val MSE: 1804.5779, MAE: 44.1504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  28%|██▊       | 14/50 [01:50<04:30,  7.52s/it, Epoch=15, Train Loss=0.8528, Val Loss=0.8471]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Train MSE: 1810.1405, MAE: 44.0823\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  30%|███       | 15/50 [01:53<04:21,  7.46s/it, Epoch=15, Train Loss=0.8528, Val Loss=0.8471]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Val MSE: 1800.9681, MAE: 44.0073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  30%|███       | 15/50 [01:58<04:21,  7.46s/it, Epoch=16, Train Loss=0.8486, Val Loss=0.8443]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Train MSE: 1805.8570, MAE: 44.0735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  32%|███▏      | 16/50 [02:00<04:11,  7.38s/it, Epoch=16, Train Loss=0.8486, Val Loss=0.8443]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Val MSE: 1799.0764, MAE: 44.0248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  32%|███▏      | 16/50 [02:05<04:11,  7.38s/it, Epoch=17, Train Loss=0.8434, Val Loss=0.8443]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Train MSE: 1811.4982, MAE: 44.0098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  34%|███▍      | 17/50 [02:07<04:02,  7.34s/it, Epoch=17, Train Loss=0.8434, Val Loss=0.8443]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Val MSE: 1804.8953, MAE: 43.9704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  34%|███▍      | 17/50 [02:13<04:02,  7.34s/it, Epoch=18, Train Loss=0.8394, Val Loss=0.8393]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Train MSE: 1802.1638, MAE: 43.8620\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  36%|███▌      | 18/50 [02:15<04:00,  7.53s/it, Epoch=18, Train Loss=0.8394, Val Loss=0.8393]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Val MSE: 1798.5681, MAE: 43.8536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  36%|███▌      | 18/50 [02:20<04:00,  7.53s/it, Epoch=19, Train Loss=0.8360, Val Loss=0.8470]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Train MSE: 1796.4574, MAE: 43.8689\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  38%|███▊      | 19/50 [02:22<03:51,  7.48s/it, Epoch=19, Train Loss=0.8360, Val Loss=0.8470]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Val MSE: 1795.6211, MAE: 43.9025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  38%|███▊      | 19/50 [02:27<03:51,  7.48s/it, Epoch=20, Train Loss=0.8327, Val Loss=0.8302]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Train MSE: 1778.8698, MAE: 43.5384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  40%|████      | 20/50 [02:30<03:42,  7.42s/it, Epoch=20, Train Loss=0.8327, Val Loss=0.8302]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Val MSE: 1776.3049, MAE: 43.5524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  40%|████      | 20/50 [02:35<03:42,  7.42s/it, Epoch=21, Train Loss=0.8299, Val Loss=0.8281]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Train MSE: 1779.6552, MAE: 43.4030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  42%|████▏     | 21/50 [02:37<03:33,  7.37s/it, Epoch=21, Train Loss=0.8299, Val Loss=0.8281]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Val MSE: 1778.6835, MAE: 43.4417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  42%|████▏     | 21/50 [02:42<03:33,  7.37s/it, Epoch=22, Train Loss=0.8265, Val Loss=0.8276]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Train MSE: 1771.9160, MAE: 43.2124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  44%|████▍     | 22/50 [02:44<03:26,  7.37s/it, Epoch=22, Train Loss=0.8265, Val Loss=0.8276]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Val MSE: 1773.5650, MAE: 43.2811\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  44%|████▍     | 22/50 [02:49<03:26,  7.37s/it, Epoch=23, Train Loss=0.8244, Val Loss=0.8233]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Train MSE: 1762.9303, MAE: 43.1658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  46%|████▌     | 23/50 [02:52<03:17,  7.32s/it, Epoch=23, Train Loss=0.8244, Val Loss=0.8233]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Val MSE: 1764.8345, MAE: 43.2300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  46%|████▌     | 23/50 [02:57<03:17,  7.32s/it, Epoch=24, Train Loss=0.8222, Val Loss=0.8231]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Train MSE: 1758.5091, MAE: 42.9360\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  48%|████▊     | 24/50 [02:59<03:09,  7.30s/it, Epoch=24, Train Loss=0.8222, Val Loss=0.8231]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Val MSE: 1763.2837, MAE: 43.0385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  48%|████▊     | 24/50 [03:04<03:09,  7.30s/it, Epoch=25, Train Loss=0.8196, Val Loss=0.8206]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Train MSE: 1762.0965, MAE: 43.1422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  50%|█████     | 25/50 [03:06<03:04,  7.38s/it, Epoch=25, Train Loss=0.8196, Val Loss=0.8206]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Val MSE: 1766.4639, MAE: 43.2424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  50%|█████     | 25/50 [03:12<03:04,  7.38s/it, Epoch=26, Train Loss=0.8174, Val Loss=0.8268]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Train MSE: 1763.6487, MAE: 43.0735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  52%|█████▏    | 26/50 [03:14<03:00,  7.51s/it, Epoch=26, Train Loss=0.8174, Val Loss=0.8268]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Val MSE: 1772.6030, MAE: 43.2221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  52%|█████▏    | 26/50 [03:20<03:00,  7.51s/it, Epoch=27, Train Loss=0.8154, Val Loss=0.8196]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Train MSE: 1750.1321, MAE: 42.8267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  54%|█████▍    | 27/50 [03:22<02:54,  7.58s/it, Epoch=27, Train Loss=0.8154, Val Loss=0.8196]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Val MSE: 1758.0904, MAE: 42.9753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  54%|█████▍    | 27/50 [03:26<02:56,  7.67s/it, Epoch=27, Train Loss=0.8154, Val Loss=0.8196]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 45\u001b[0m\n\u001b[1;32m     43\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(outputs, batch_y)\n\u001b[1;32m     44\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m---> 45\u001b[0m     \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m     train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     49\u001b[0m train_loss \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(train_loader)\n",
      "File \u001b[0;32m/kaggle/env/lib/python3.11/site-packages/torch/optim/optimizer.py:379\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    377\u001b[0m \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m cast(Optimizer, \u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    378\u001b[0m profile_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOptimizer.step#\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.step\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 379\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprofiler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecord_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprofile_name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    380\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# call optimizer step pre hooks\u001b[39;49;00m\n\u001b[1;32m    381\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpre_hook\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_global_optimizer_pre_hooks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_optimizer_step_pre_hooks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    382\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresult\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mpre_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/kaggle/env/lib/python3.11/site-packages/torch/autograd/profiler.py:605\u001b[0m, in \u001b[0;36mrecord_function.__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    604\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__enter__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 605\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecord \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprofiler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_record_function_enter_new\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    606\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\n\u001b[1;32m    607\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m/kaggle/env/lib/python3.11/site-packages/torch/_ops.py:854\u001b[0m, in \u001b[0;36mOpOverloadPacket.__call__\u001b[0;34m(self_, *args, **kwargs)\u001b[0m\n\u001b[1;32m    846\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(self_, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):  \u001b[38;5;66;03m# noqa: B902\u001b[39;00m\n\u001b[1;32m    847\u001b[0m     \u001b[38;5;66;03m# use `self_` to avoid naming collide with aten ops arguments that\u001b[39;00m\n\u001b[1;32m    848\u001b[0m     \u001b[38;5;66;03m# named \"self\". This way, all the aten ops can be called by kwargs.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    852\u001b[0m     \u001b[38;5;66;03m# We save the function ptr as the `op` attribute on\u001b[39;00m\n\u001b[1;32m    853\u001b[0m     \u001b[38;5;66;03m# OpOverloadPacket to access it here.\u001b[39;00m\n\u001b[0;32m--> 854\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mself_\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_op\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "max_num_epochs = 50\n",
    "best_val_loss = float('inf')\n",
    "patience = 5\n",
    "no_improve = 0\n",
    "log_original_loss_every = 1\n",
    "\n",
    "def calculate_original_losses(loader, model, scaler, dataset_name):\n",
    "    total_mse = 0\n",
    "    total_mae = 0\n",
    "    total_samples = 0\n",
    "    mse_criterion = nn.MSELoss(reduction='sum')\n",
    "    mae_criterion = nn.L1Loss(reduction='sum')\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_X, batch_y in loader:\n",
    "            batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "            outputs = model(batch_X)\n",
    "            \n",
    "            outputs_original = torch.from_numpy(scaler_y.inverse_transform(outputs.cpu().numpy())).to(device)\n",
    "            batch_y_original = torch.from_numpy(scaler_y.inverse_transform(batch_y.cpu().numpy())).to(device)\n",
    "            \n",
    "            mse = mse_criterion(outputs_original, batch_y_original)\n",
    "            mae = mae_criterion(outputs_original, batch_y_original)\n",
    "            \n",
    "            total_mse += mse.item()\n",
    "            total_mae += mae.item()\n",
    "            total_samples += batch_y.size(0)\n",
    "    \n",
    "    mse = total_mse / total_samples\n",
    "    mae = total_mae / total_samples\n",
    "    print(f\"Original {dataset_name} MSE: {mse:.4f}, MAE: {mae:.4f}\")\n",
    "    return mse, mae\n",
    "\n",
    "pbar = tqdm(range(max_num_epochs), desc=\"Training Progress\")\n",
    "for epoch in pbar:\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for batch_X, batch_y in train_loader:\n",
    "        batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_X)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "    \n",
    "    train_loss /= len(train_loader)\n",
    "    \n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_X, batch_y in val_loader:\n",
    "            batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "            outputs = model(batch_X)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            val_loss += loss.item()\n",
    "    \n",
    "    val_loss /= len(val_loader)\n",
    "    \n",
    "    pbar.set_postfix({\n",
    "        'Epoch': epoch+1,\n",
    "        'Train Loss': f'{train_loss:.4f}',\n",
    "        'Val Loss': f'{val_loss:.4f}'\n",
    "    })\n",
    "    \n",
    "    if (epoch + 1) % log_original_loss_every == 0:\n",
    "        train_mse, train_mae = calculate_original_losses(train_loader, model, scaler_y, \"Train\")\n",
    "        val_mse, val_mae = calculate_original_losses(val_loader, model, scaler_y, \"Val\")\n",
    "    \n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(model.state_dict(), 'best_model.pth')\n",
    "        no_improve = 0\n",
    "    else:\n",
    "        no_improve += 1\n",
    "        if no_improve == patience:\n",
    "            print(\"\\nEarly stopping!\")\n",
    "            break\n",
    "\n",
    "model.load_state_dict(torch.load('best_model.pth'))\n",
    "print(\"Training completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Evaluate the model on Test Set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_loader, scaler_y, device):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    true_values = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_X, batch_y in test_loader:\n",
    "            batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "            outputs = model(batch_X)\n",
    "            predictions.append(outputs.cpu().numpy())\n",
    "            true_values.append(batch_y.cpu().numpy())\n",
    "\n",
    "    predictions = np.concatenate(predictions)\n",
    "    true_values = np.concatenate(true_values)\n",
    "\n",
    "    predictions_original = scaler_y.inverse_transform(predictions)\n",
    "    true_values_original = scaler_y.inverse_transform(true_values)\n",
    "\n",
    "    mse = mean_squared_error(true_values_original, predictions_original)\n",
    "    mae = mean_absolute_error(true_values_original, predictions_original)\n",
    "    rmse = np.sqrt(mse)\n",
    "    max_error = np.max(np.abs(predictions_original - true_values_original))\n",
    "    r2 = r2_score(true_values_original, predictions_original)\n",
    "\n",
    "    return {\n",
    "        'predictions': predictions_original,\n",
    "        'true_values': true_values_original,\n",
    "        'mse': mse,\n",
    "        'mae': mae,\n",
    "        'rmse': rmse,\n",
    "        'max_error': max_error,\n",
    "        'r2': r2\n",
    "    }\n",
    "\n",
    "# Load the best model\n",
    "model.load_state_dict(torch.load('best_model.pth'))\n",
    "\n",
    "# Evaluate the best model\n",
    "results = evaluate_model(model, test_loader, scaler_y, device)\n",
    "\n",
    "# Print results\n",
    "print(\"\\nMetrics for the best model:\")\n",
    "print(f\"Mean Squared Error: {results['mse']:.4f}\")\n",
    "print(f\"Mean Absolute Error: {results['mae']:.4f}\")\n",
    "print(f\"Root Mean Squared Error: {results['rmse']:.4f}\")\n",
    "print(f\"Maximum Absolute Error: {results['max_error']:.4f}\")\n",
    "print(f\"R-squared Score: {results['r2']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Interactive Visulization** (might be buggy, not checked/fixed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_trajectory(trajectory_index, results):\n",
    "    predictions = results['predictions']\n",
    "    true_values = results['true_values']\n",
    "    \n",
    "    idx = trajectory_index * 100\n",
    "    true_traj = true_values[idx:idx+100]\n",
    "    pred_traj = predictions[idx:idx+100]\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(true_traj[:, 0], true_traj[:, 1], label='True', color='blue')\n",
    "    plt.plot(pred_traj[:, 0], pred_traj[:, 1], label='Predicted', color='red', linestyle='--')\n",
    "    \n",
    "    plt.title(f'Trajectory {trajectory_index}')\n",
    "    plt.legend()\n",
    "    plt.xlabel('X')\n",
    "    plt.ylabel('Y')\n",
    "    plt.grid(True, linestyle='--', alpha=0.7)\n",
    "    \n",
    "    plt.plot(true_traj[0, 0], true_traj[0, 1], 'go', markersize=8, label='Start')\n",
    "    plt.plot(true_traj[-1, 0], true_traj[-1, 1], 'ro', markersize=8, label='End')\n",
    "    \n",
    "    mid = len(true_traj) // 2\n",
    "    plt.annotate('', xy=(true_traj[mid+1, 0], true_traj[mid+1, 1]),\n",
    "                 xytext=(true_traj[mid, 0], true_traj[mid, 1]),\n",
    "                 arrowprops=dict(facecolor='blue', shrink=0.05))\n",
    "    plt.annotate('', xy=(pred_traj[mid+1, 0], pred_traj[mid+1, 1]),\n",
    "                 xytext=(pred_traj[mid, 0], pred_traj[mid, 1]),\n",
    "                 arrowprops=dict(facecolor='red', shrink=0.05))\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "# Create interactive plot\n",
    "max_trajectories = len(results['predictions']) // 100 - 1\n",
    "\n",
    "interact(plot_trajectory,\n",
    "         trajectory_index=widgets.IntSlider(min=0, max=max_trajectories, step=1, description='Trajectory:'),\n",
    "         results=fixed(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_trajectory_point(trajectory_index, point_index, results):\n",
    "    predictions = results['predictions']\n",
    "    true_values = results['true_values']\n",
    "    \n",
    "    # Determine the number of points per trajectory\n",
    "    points_per_trajectory = results.get('points_per_trajectory', 100)  # Default to 100 if not specified\n",
    "    \n",
    "    idx_start = trajectory_index * points_per_trajectory\n",
    "    idx_end = idx_start + points_per_trajectory\n",
    "    \n",
    "    true_traj = true_values[idx_start:idx_end]\n",
    "    pred_traj = predictions[idx_start:idx_end]\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(true_traj[:, 0], true_traj[:, 1], label='True', color='blue')\n",
    "    plt.plot(pred_traj[:, 0], pred_traj[:, 1], label='Predicted', color='red', linestyle='--')\n",
    "    \n",
    "    plt.title(f'Trajectory {trajectory_index}, Point {point_index}')\n",
    "    plt.legend()\n",
    "    plt.xlabel('X')\n",
    "    plt.ylabel('Y')\n",
    "    plt.grid(True, linestyle='--', alpha=0.7)\n",
    "    \n",
    "    plt.plot(true_traj[0, 0], true_traj[0, 1], 'go', markersize=8, label='Start')\n",
    "    plt.plot(true_traj[-1, 0], true_traj[-1, 1], 'ro', markersize=8, label='End')\n",
    "    \n",
    "    # Highlight the selected point\n",
    "    plt.plot(true_traj[point_index, 0], true_traj[point_index, 1], 'bo', markersize=10, label='Selected (True)')\n",
    "    plt.plot(pred_traj[point_index, 0], pred_traj[point_index, 1], 'mo', markersize=10, label='Selected (Predicted)')\n",
    "    \n",
    "    plt.legend()\n",
    "    \n",
    "    # Display coordinates and error\n",
    "    true_coord = true_traj[point_index]\n",
    "    pred_coord = pred_traj[point_index]\n",
    "    error = np.linalg.norm(true_coord - pred_coord)\n",
    "    \n",
    "    info_text = f'True: ({true_coord[0]:.2f}, {true_coord[1]:.2f})\\n'\n",
    "    info_text += f'Predicted: ({pred_coord[0]:.2f}, {pred_coord[1]:.2f})\\n'\n",
    "    info_text += f'Error: {error:.2f}'\n",
    "    \n",
    "    plt.text(0.05, 0.95, info_text, transform=plt.gca().transAxes, verticalalignment='top', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "# Determine the number of trajectories and points per trajectory\n",
    "total_points = len(results['predictions'])\n",
    "points_per_trajectory = results.get('points_per_trajectory', 100)  # Default to 100 if not specified\n",
    "num_trajectories = total_points // points_per_trajectory\n",
    "\n",
    "# Create interactive plot with trajectory and point selection\n",
    "interact(plot_trajectory_point,\n",
    "         trajectory_index=widgets.IntSlider(min=0, max=num_trajectories-1, step=1, description='Trajectory:'),\n",
    "         point_index=widgets.IntSlider(min=0, max=points_per_trajectory-1, step=1, description='Point:'),\n",
    "         results=fixed(results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Save the Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_id = f\"{socket.gethostname()}_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "dest_path = f\"saved_models/best_model_{unique_id}.pth\"\n",
    "\n",
    "os.makedirs('saved_models', exist_ok=True)\n",
    "!cp best_model.pth {dest_path}\n",
    "\n",
    "print(f\"Best model copied and saved as '{dest_path}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
