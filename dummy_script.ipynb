{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In each data fold, there is a raw data subfolder and a syn data subfolder, which represent the raw data collection without synchronisation but with high precise timestep, and the synchronised data but without high precise timestep.\n",
    "\n",
    "Here is the header of the sensor file and ground truth file.\n",
    "\n",
    "## vicon (vi*.csv)\n",
    "\n",
    "Time  Header  translation.x translation.y translation.z rotation.x rotation.y rotation.z rotation.w\n",
    "\n",
    "## Sensors (imu*.csv)\n",
    "\n",
    "Time attitude_roll(radians) attitude_pitch(radians) attitude_yaw(radians) rotation_rate_x(radians/s) rotation_rate_y(radians/s) rotation_rate_z(radians/s) gravity_x(G) gravity_y(G) gravity_z(G) user_acc_x(G) user_acc_y(G) user_acc_z(G) magnetic_field_x(microteslas) magnetic_field_y(microteslas) magnetic_field_z(microteslas)\n",
    "\n",
    "## Structure\n",
    "\n",
    "In this folder\n",
    "```\n",
    "user@fedora ~/C/magnetic_localization (master)> ls data/Oxford\\ Inertial\\ Odometry\\ Dataset/handheld/data1/syn/\n",
    "imu1.csv*  imu4.csv*  imu7.csv*  vi3.csv*  vi6.csv*\n",
    "imu2.csv*  imu5.csv*  vi1.csv*   vi4.csv*  vi7.csv*\n",
    "imu3.csv*  imu6.csv*  vi2.csv*   vi5.csv*\n",
    "user@fedora ~/C/magnetic_localization (master)> ls data/Oxford\\ Inertial\\ Odometry\\ Dataset/handheld/data2/syn/\n",
    "imu1.csv*  imu2.csv*  imu3.csv*  vi1.csv*  vi2.csv*  vi3.csv*\n",
    "user@fedora ~/C/magnetic_localization (master)> ls data/Oxford\\ Inertial\\ Odometry\\ Dataset/handheld/\n",
    "data1/  data3/  data5/          Test.txt*\n",
    "data2/  data4/  handheld.xlsx*  Train.txt*\n",
    "user@fedora ~/C/magnetic_localization (master)> pwd\n",
    "/home/user/Code/magnetic_localization\n",
    "```\n",
    "\n",
    "Also like each of them are the same length, so no need to sync the timesteps\n",
    "```\n",
    "user@fedora ~/C/magnetic_localization (master)> cat data/Oxford\\ Inertial\\ Odometry\\ Dataset/handheld/data1/syn/imu2.csv |wc\n",
    "  23446   23446 3282548\n",
    "user@fedora ~/C/magnetic_localization (master)> cat data/Oxford\\ Inertial\\ Odometry\\ Dataset/handheld/data1/syn/vi2.csv |wc\n",
    "  23446   23446 1740520\n",
    "```\n",
    "\n",
    "Just fucking ignore the Time and Header\n",
    "\n",
    "## Goal\n",
    "\n",
    "Our goal is to predict the current `x`, `y`, `z` based on the previous all previous data(but not previous `x`, `y`, `z`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Below is a dumb load of magnetic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sequences in X_train: 20\n",
      "Number of sequences in y_train: 20\n",
      "Number of sequences in X_test: 4\n",
      "Number of sequences in y_test: 4\n",
      "\n",
      "Shapes of sequences in X_train:\n",
      "Sequence 1: (37602, 4)\n",
      "Sequence 2: (23446, 4)\n",
      "Sequence 3: (18850, 4)\n",
      "Sequence 4: (21641, 4)\n",
      "Sequence 5: (32160, 4)\n",
      "Sequence 6: (32537, 4)\n",
      "Sequence 7: (14098, 4)\n",
      "Sequence 8: (32618, 4)\n",
      "Sequence 9: (31179, 4)\n",
      "Sequence 10: (30059, 4)\n",
      "Sequence 11: (30756, 4)\n",
      "Sequence 12: (37910, 4)\n",
      "Sequence 13: (60868, 4)\n",
      "Sequence 14: (53796, 4)\n",
      "Sequence 15: (38322, 4)\n",
      "Sequence 16: (31724, 4)\n",
      "Sequence 17: (32228, 4)\n",
      "Sequence 18: (60580, 4)\n",
      "Sequence 19: (43841, 4)\n",
      "Sequence 20: (35017, 4)\n",
      "\n",
      "Shapes of sequences in X_test:\n",
      "Sequence 1: (31040, 4)\n",
      "Sequence 2: (59445, 4)\n",
      "Sequence 3: (55979, 4)\n",
      "Sequence 4: (36578, 4)\n",
      "\n",
      "Training set statistics:\n",
      "Min length: 14098\n",
      "Max length: 60868\n",
      "Mean length: 34961.60\n",
      "Median length: 32382.50\n",
      "\n",
      "Test set statistics:\n",
      "Min length: 31040\n",
      "Max length: 59445\n",
      "Mean length: 45760.50\n",
      "Median length: 46278.50\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Base path to the handheld folder\n",
    "base_path = './data/Oxford Inertial Odometry Dataset/handheld/'\n",
    "\n",
    "# Function to read and process IMU data\n",
    "def process_imu_data(file_path):\n",
    "    df = pd.read_csv(file_path, header=None)\n",
    "    mag_x, mag_y, mag_z = df.iloc[:, -3], df.iloc[:, -2], df.iloc[:, -1]\n",
    "    mag_total = np.sqrt(mag_x**2 + mag_y**2 + mag_z**2)\n",
    "    return np.column_stack((mag_x, mag_y, mag_z, mag_total))\n",
    "\n",
    "# Function to read and process Vicon data\n",
    "def process_vicon_data(file_path):\n",
    "    df = pd.read_csv(file_path, header=None)\n",
    "    x, y, z = df.iloc[:, 2], df.iloc[:, 3], df.iloc[:, 4]\n",
    "    return np.column_stack((x, y, z))\n",
    "\n",
    "# Read train and test folder names\n",
    "with open(os.path.join(base_path, 'Train.txt'), 'r') as f:\n",
    "    train_folders = f.read().splitlines()\n",
    "with open(os.path.join(base_path, 'Test.txt'), 'r') as f:\n",
    "    test_folders = f.read().splitlines()\n",
    "\n",
    "# Lists to store sequences\n",
    "X_train, y_train = [], []\n",
    "X_test, y_test = [], []\n",
    "\n",
    "# Process data for each folder\n",
    "for data_folder in train_folders + test_folders:\n",
    "    folder_path = os.path.join(base_path, data_folder, 'syn')\n",
    "    \n",
    "    if not os.path.exists(folder_path):\n",
    "        print(f\"Folder not found: {folder_path}\")\n",
    "        continue\n",
    "\n",
    "    imu_files = sorted([f for f in os.listdir(folder_path) if f.startswith('imu')])\n",
    "    vicon_files = sorted([f for f in os.listdir(folder_path) if f.startswith('vi')])\n",
    "\n",
    "    for imu_file, vicon_file in zip(imu_files, vicon_files):\n",
    "        imu_data = process_imu_data(os.path.join(folder_path, imu_file))\n",
    "        vicon_data = process_vicon_data(os.path.join(folder_path, vicon_file))\n",
    "\n",
    "        if data_folder in train_folders:\n",
    "            X_train.append(imu_data)\n",
    "            y_train.append(vicon_data)\n",
    "        else:\n",
    "            X_test.append(imu_data)\n",
    "            y_test.append(vicon_data)\n",
    "\n",
    "print(\"Number of sequences in X_train:\", len(X_train))\n",
    "print(\"Number of sequences in y_train:\", len(y_train))\n",
    "print(\"Number of sequences in X_test:\", len(X_test))\n",
    "print(\"Number of sequences in y_test:\", len(y_test))\n",
    "\n",
    "print(\"\\nShapes of sequences in X_train:\")\n",
    "for i, seq in enumerate(X_train):\n",
    "    print(f\"Sequence {i+1}: {seq.shape}\")\n",
    "\n",
    "print(\"\\nShapes of sequences in X_test:\")\n",
    "for i, seq in enumerate(X_test):\n",
    "    print(f\"Sequence {i+1}: {seq.shape}\")\n",
    "\n",
    "# Calculate and print some statistics\n",
    "train_lengths = [len(seq) for seq in X_train]\n",
    "test_lengths = [len(seq) for seq in X_test]\n",
    "\n",
    "print(\"\\nTraining set statistics:\")\n",
    "print(f\"Min length: {min(train_lengths)}\")\n",
    "print(f\"Max length: {max(train_lengths)}\")\n",
    "print(f\"Mean length: {np.mean(train_lengths):.2f}\")\n",
    "print(f\"Median length: {np.median(train_lengths):.2f}\")\n",
    "\n",
    "print(\"\\nTest set statistics:\")\n",
    "print(f\"Min length: {min(test_lengths)}\")\n",
    "print(f\"Max length: {max(test_lengths)}\")\n",
    "print(f\"Mean length: {np.mean(test_lengths):.2f}\")\n",
    "print(f\"Median length: {np.median(test_lengths):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
